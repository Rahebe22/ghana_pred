{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine pre-trained model Ghana per tile\n",
    "\n",
    "Using high quality labels just from Ghana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Q4kB9xwMqE6s"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SC1iL8cfVqEr"
   },
   "outputs": [],
   "source": [
    "repo = \"deeplearner\"\n",
    "clone_path = \"/home/mappers/projects/\"\n",
    "repo_clone_path = f\"{clone_path}/{repo}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y4rXZmhHWGvs"
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(repo_clone_path, 'deeplearner/'))\n",
    "sys.path.insert(0, repo_clone_path)\n",
    "import deeplearner\n",
    "importlib.reload(deeplearner)\n",
    "from deeplearner.models import *\n",
    "from deeplearner.losses import *\n",
    "from deeplearner.datatorch2 import *\n",
    "from deeplearner.utils import *\n",
    "from deeplearner.compiler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Lrh1bGe9WLUG"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"source_dir\" : \"/home/mappers/data/\",\n",
    "    \"working_dir\" : \"/home/mappers/tmp/gh_cg_tz_ng/refine_ghana_per_tile\",\n",
    "    \n",
    "    # train and validation dataset\n",
    "    # \"train_csv_name\" : \"catalog_gh_cg_tz_ng_v1.csv\",\n",
    "    \"train_pickle_name\" : \"refine_ghana_per_tile.pickle\",\n",
    "    \"val_pickle_name\" : \"val_ghana_per_tile.pickle\",\n",
    "    \"lbl_patchSize\" : 200,\n",
    "    \"one_side_buffer\" : 12,\n",
    "    \"tile_buffer\" : 11,\n",
    "    \"img_path_cols\" : [\"dir_os\"],\n",
    "    \"norm_stats_type\" : \"local_per_tile\",\n",
    "    \"label_path_col\" : \"dir_label\",\n",
    "    \"train_lbl_quality_groups\" : (3, 4),\n",
    "    \"val_lbl_quality_groups\" : (3, 4),\n",
    "    \"transformations\" : \n",
    "        ['vflip', 'hflip', 'rotate', 'resize', 'shift_brightness'],\n",
    "    \"rotationDegree\" : (-90, 90),\n",
    "    \"bshift_band_grouping\" : [4],\n",
    "\n",
    "    # train and validation DataLoader\n",
    "    \"train_BatchSize\" : 32,\n",
    "    \"val_BatchSize\" : 2,\n",
    "\n",
    "    # Model\n",
    "    \"input_channels\" : 4,\n",
    "    \"n_classes\" : 3,\n",
    "\n",
    "    # Model compiler\n",
    "    \"gpuDevices\" : [0],\n",
    "    \"params_init_path\" : \n",
    "        (\n",
    "            f\"s3://activemapper/DL/models/gh_cg_tz_ng/local_per_tile/\"\n",
    "            f\"unet_params.pth\"\n",
    "        ),\n",
    "    \"freeze_layer_ls\" : list(range(58)),\n",
    "    \n",
    "\n",
    "    # Model fitting\n",
    "    \"epochs\" : 20,\n",
    "    \"optimizer\": \"nesterov\",\n",
    "    \"LR\" : 0.01, \n",
    "    \"LR_policy\" : \"PolynomialLR\",\n",
    "    \"criterion\" : \"BalancedTverskyFocalLoss(gamma = 0.9)\",\n",
    "    \"momentum\" : 0.95,\n",
    "    \"resume\" : False,\n",
    "    \"resume_epoch\" : None,\n",
    "    \"bucket\" : \"activemapper\",\n",
    "    \"prefix_out\": \"DL/models/gh_cg_tz_ng/refine_ghana_per_tile\",\n",
    "\n",
    "    #prediction \n",
    "}\n",
    "\n",
    "pickle_dir = Path(config[\"source_dir\"]) / \"pickles\"\n",
    "if not os.path.exists(pickle_dir):\n",
    "    os.makedirs(pickle_dir)\n",
    "\n",
    "train_pickle_path = pickle_dir / config[\"train_pickle_name\"]\n",
    "val_pickle_path = pickle_dir / config[\"val_pickle_name\"]\n",
    "\n",
    "if not os.path.exists(config[\"working_dir\"]):\n",
    "    os.makedirs(config[\"working_dir\"])\n",
    "\n",
    "log_dir = Path(config[\"working_dir\"]) / \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZjX9goy8CeT",
    "tags": []
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEU3HjsOFBXk"
   },
   "source": [
    "**Step 1.** Setup seeding to make the experiment reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4rI6OmRsFRvq"
   },
   "outputs": [],
   "source": [
    "make_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_4skkAt8Srk"
   },
   "source": [
    "**Step 2.** Load the train and val datasets (i.e. divide the dataset into mini-batches after applying the augmentation, convert to tensor and put them on GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VIL29r0YXK-D"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(train_pickle_path)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"train_BatchSize\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-RzHFlbsXVoe"
   },
   "outputs": [],
   "source": [
    "validation_dataset = load_dataset(val_pickle_path)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=config[\"val_BatchSize\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzUV9cT79JF0"
   },
   "source": [
    "**Step 3.** Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M-AJ8_JDXZwx"
   },
   "outputs": [],
   "source": [
    "model = eval('unet'.lower())(config[\"input_channels\"], config[\"n_classes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_qltnA9bPp"
   },
   "source": [
    "**Step 4.** Compile\n",
    "\n",
    "The model Compiler is responsible for: \n",
    "1) handling the model parallelism on multiple GPUs, \n",
    "2) loading existing model parametrs if needed and\n",
    "3) freeze user-defined layers of model if model-based transfer learning is pursued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NJp_ZYL3Xhn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GPU available----------\n",
      "total number of trainable parameters: 20.5M\n",
      "---------- Pre-trained model compiled successfully ----------\n"
     ]
    }
   ],
   "source": [
    "model = ModelCompiler(\n",
    "    model, buffer = config[\"one_side_buffer\"], \n",
    "    gpuDevices = config[\"gpuDevices\"], \n",
    "    params_init = config[\"params_init_path\"],\n",
    "    freeze_params = config[\"freeze_layer_ls\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJXdlPWBbkM"
   },
   "source": [
    "**Step 5.** train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dLzNotwQXnnH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start training --------------------------\n",
      "[1/20]\n",
      "train loss:0.763514104343596\n",
      "validation loss: 0.5836250590005269\n",
      "LR: 0.009919999758550428\n",
      "time: 24\n",
      "[2/20]\n",
      "train loss:0.7530495552789598\n",
      "validation loss: 0.5842316497427722\n",
      "LR: 0.009919999758550428\n",
      "time: 23\n",
      "[3/20]\n",
      "train loss:0.75078642084485\n",
      "validation loss: 0.58841101002569\n",
      "LR: 0.009839837734062955\n",
      "time: 22\n",
      "[4/20]\n",
      "train loss:0.7539393816675458\n",
      "validation loss: 0.5855828745601078\n",
      "LR: 0.009759511943429413\n",
      "time: 23\n",
      "[5/20]\n",
      "train loss:0.7506121794382731\n",
      "validation loss: 0.5802314729585002\n",
      "LR: 0.009679020358515226\n",
      "time: 23\n",
      "[6/20]\n",
      "train loss:0.7562589304787772\n",
      "validation loss: 0.5814116720420619\n",
      "LR: 0.009598360904656872\n",
      "time: 23\n",
      "[7/20]\n",
      "train loss:0.7543824400220599\n",
      "validation loss: 0.5803205695624153\n",
      "LR: 0.009517531459092827\n",
      "time: 23\n",
      "[8/20]\n",
      "train loss:0.7557718299684071\n",
      "validation loss: 0.5820903285872191\n",
      "LR: 0.009436529849324329\n",
      "time: 23\n",
      "[9/20]\n",
      "train loss:0.7492261557351976\n",
      "validation loss: 0.5906727826533218\n",
      "LR: 0.00935535385140202\n",
      "time: 23\n",
      "[10/20]\n",
      "train loss:0.7533758935474214\n",
      "validation loss: 0.5857608420075848\n",
      "LR: 0.009274001188134292\n",
      "time: 22\n",
      "[11/20]\n",
      "train loss:0.754722998255775\n",
      "validation loss: 0.5784704871398086\n",
      "LR: 0.009192469527212815\n",
      "time: 23\n",
      "[12/20]\n",
      "train loss:0.7485901003792172\n",
      "validation loss: 0.5855595032529285\n",
      "LR: 0.00911075647925052\n",
      "time: 22\n",
      "[13/20]\n",
      "train loss:0.7473261753718058\n",
      "validation loss: 0.5809093547364076\n",
      "LR: 0.00902885959572685\n",
      "time: 23\n",
      "[14/20]\n",
      "train loss:0.75095077923366\n",
      "validation loss: 0.5812204831900696\n",
      "LR: 0.008946776366834828\n",
      "time: 23\n",
      "[15/20]\n",
      "train loss:0.7488402156602769\n",
      "validation loss: 0.5802906146428237\n",
      "LR: 0.008864504219224079\n",
      "time: 22\n",
      "[16/20]\n",
      "train loss:0.7504101480756488\n",
      "validation loss: 0.5872778006984541\n",
      "LR: 0.008782040513633455\n",
      "time: 22\n",
      "[17/20]\n",
      "train loss:0.7501207306271508\n",
      "validation loss: 0.5882992639516791\n",
      "LR: 0.008699382542406575\n",
      "time: 23\n",
      "[18/20]\n",
      "train loss:0.7511346056347802\n",
      "validation loss: 0.5831096457317472\n",
      "LR: 0.008616527526882934\n",
      "time: 22\n",
      "[19/20]\n",
      "train loss:0.7520536780357361\n",
      "validation loss: 0.5811574559930401\n",
      "LR: 0.008533472614656866\n",
      "time: 23\n",
      "[20/20]\n",
      "train loss:0.7489429229781741\n",
      "validation loss: 0.5912680120983471\n",
      "LR: 0.008450214876695889\n",
      "time: 22\n",
      "-------------------------- Training finished in 472s --------------------------\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataloader, \n",
    "    validation_dataloader, \n",
    "    epochs = config[\"epochs\"], \n",
    "    optimizer_name = config[\"optimizer\"], \n",
    "    lr_init = config[\"LR\"], \n",
    "    lr_policy = config[\"LR_policy\"], \n",
    "    criterion = config[\"criterion\"], \n",
    "    momentum = config[\"momentum\"],\n",
    "    resume = config[\"resume\"], \n",
    "    resume_epoch = config[\"resume_epoch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dbXlGrWCOuC"
   },
   "source": [
    "**Step 6.** Save the trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "T9GklbduXw5j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss files uploaded to s3\n",
      "model parameters uploaded to s3!, at  DL/models/gh_cg_tz_ng/refine_ghana_per_tile\n"
     ]
    }
   ],
   "source": [
    "model.save(bucket=config[\"bucket\"], outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOxDlWhJBxYS"
   },
   "source": [
    "**Step 7.** Evaluate the trained model against the evaluation dataset and report a number of accuracy metrics in a csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9C-XLAYwXvqX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start evaluation --------------------------\n",
      "-------------------------- Evaluation finished in 19s --------------------------\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validation_dataloader, bucket=config[\"bucket\"], \n",
    "               outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJU31PmpCiYr"
   },
   "source": [
    "**Step 8.** Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJI_yy7hX0nn"
   },
   "outputs": [],
   "source": [
    "def load_pred_data(dir_data, pred_patch_size, pred_buffer, pred_composite_buffer, \n",
    "                   pred_batch, catalog, catalog_row, img_path_cols, average_neighbors=False):\n",
    "    def load_single_tile(catalog_ind = catalog_row):\n",
    "        dataset = planetData(dir_data, catalog, pred_patch_size, pred_buffer, \n",
    "                             pred_composite_buffer, \"predict\", \n",
    "                             catalogIndex=catalog_ind, imgPathCols=img_path_cols)\n",
    "        data_loader = DataLoader(dataset, batch_size=pred_batch, shuffle=False)\n",
    "        meta = dataset.meta\n",
    "        tile = dataset.tile\n",
    "        return data_loader, meta, tile\n",
    "\n",
    "    if average_neighbors == True:\n",
    "        catalog[\"tile_col_row\"] = catalog.apply(lambda x: \"{}_{}\".format(x['tile_col'], x['tile_row']), axis=1)\n",
    "        tile_col = catalog.iloc[catalog_row].tile_col\n",
    "        tile_row = catalog.iloc[catalog_row].tile_row\n",
    "        row_dict = {\n",
    "            \"center\": catalog_row,\n",
    "            \"top\": catalog.query('tile_col=={} & tile_row=={}'.format(tile_col, tile_row - 1)).iloc[0].name \\\n",
    "                if \"{}_{}\".format(tile_col, tile_row - 1) in list(catalog.tile_col_row) else None,\n",
    "            \"left\" : catalog.query('tile_col=={} & tile_row=={}'.format(tile_col - 1, tile_row)).iloc[0].name \\\n",
    "                if \"{}_{}\".format(tile_col - 1, tile_row) in list(catalog.tile_col_row) else None,\n",
    "            \"right\" : catalog.query('tile_col=={} & tile_row=={}'.format(tile_col + 1, tile_row)).iloc[0].name \\\n",
    "                if \"{}_{}\".format(tile_col + 1, tile_row) in list(catalog.tile_col_row) else None,\n",
    "            \"bottom\": catalog.query('tile_col=={} & tile_row=={}'.format(tile_col, tile_row + 1)).iloc[0].name \\\n",
    "                if \"{}_{}\".format(tile_col, tile_row + 1) in list(catalog.tile_col_row) else None,\n",
    "            }\n",
    "        dataset_dict = {k:load_single_tile(catalog_ind = row_dict[k]) if row_dict[k] is not None else None \n",
    "                        for k in row_dict.keys()}\n",
    "        return dataset_dict\n",
    "    # direct crop edge pixels\n",
    "    else:\n",
    "        return load_single_tile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EU-l_ewFYiQY"
   },
   "outputs": [],
   "source": [
    "prefix_out = 'DL/predictions/gh_cg_tz/DFUNet_WithoutAttention_05032022/ghana'\n",
    "catalog = 'catalogs/predict/catalog_ghana_retiled_8.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB03NBvhYn8p"
   },
   "outputs": [],
   "source": [
    "pred_catalog = pd.read_csv(os.path.join(dir_data, catalog))\n",
    "inds = pred_catalog.query(\"type == 'center'\").index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBxfyK9OYsZK"
   },
   "outputs": [],
   "source": [
    "for i in inds:\n",
    "    print(\"Predicting on index %s\" % (i))\n",
    "    pred_dataloader = load_pred_data(\n",
    "        dir_data, pred_patch_size, pred_buffer, pred_composite_buffer, \n",
    "        pred_batch, pred_catalog, i, img_path_cols, \n",
    "        average_neighbors = average_neighbors\n",
    "    )\n",
    "    p = model.predict(\n",
    "        pred_dataloader, bucket, prefix_out, \n",
    "        pred_buffer, averageNeighbors=average_neighbors, \n",
    "        shrinkBuffer = shrink_pixels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLksaEmtY9jb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "fig, ax = pyplot.subplots(3,3, figsize=(15,20))\n",
    "for i in range(len(inds)):\n",
    "    col, row = pred_catalog.iloc[inds[i]][['tile_col', 'tile_row']]\n",
    "    image_path = 's3://{}/{}/Score_1/score_c{}_r{}.tif'.\\\n",
    "        format(bucket, prefix_out, col, row)\n",
    "    img = rasterio.open(image_path).read()\n",
    "    show(img.astype('uint8'), ax = ax[math.floor(i/3)][i%3], title=os.path.basename(image_path))\n",
    "    \n",
    "image_path\n",
    "pyplot.savefig(\"score_map_unet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukABIH0uZbG7"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "\n",
    "def findRowCol(filename):\n",
    "    col = re.findall(r\"(?<=_c)\\d\\d\\d(?=_r)\", filename)[0]\n",
    "    row = re.findall(r\"(?<=_r)\\d\\d\\d(?=.tif)\", filename)[0]\n",
    "    return int(row), int(col)\n",
    "\n",
    "def rescale_image(image, bands=(0, 1, 2, 3)):\n",
    "    img = reshape_as_image(image.read())[:,:,bands]\n",
    "    max_vals = [img[:, :, band].max() for band in range(img.shape[-1])]\n",
    "    img = img.astype('float64')\n",
    "    for band in bands:\n",
    "        band_vals = img[:, :, band]\n",
    "        img[:, :, band] = band_vals / max_vals[band]\n",
    "\n",
    "    return img\n",
    "\n",
    "path_to_unet_tiles = 'predicted_tiles_unet'\n",
    "path_to_dfunet_noattn_tiles = 'predicted_tiles_dfunet_noattn'\n",
    "path_to_simpledfunet_tiles = 'predicted_tiles_simpledfunet'\n",
    "\n",
    "predicted_unet = os.listdir(path_to_unet_tiles)\n",
    "predicted_dfunet = os.listdir(path_to_dfunet_noattn_tiles)\n",
    "predicted_simpledfunet = os.listdir(path_to_simpledfunet_tiles)\n",
    "\n",
    "assert(predicted_dfunet == predicted_unet == predicted_simpledfunet)\n",
    "n = len(predicted_unet)\n",
    "assert(len(os.listdir('dir_os')) == len(os.listdir('dir_gs')) == n)\n",
    "\n",
    "fig, ax = pyplot.subplots(n, 4, figsize=(18,40))\n",
    "\n",
    "os_images = []\n",
    "for i in range(n):\n",
    "    unet_path = os.path.join(path_to_unet_tiles, predicted_unet[i])\n",
    "    img = rasterio.open(unet_path).read()\n",
    "    show(img.astype('uint8'), ax = ax[i][0], title=\"UNet_\"+os.path.basename(unet_path)[:-4])\n",
    "    \n",
    "    dfunet_path = os.path.join(path_to_dfunet_noattn_tiles, predicted_unet[i])\n",
    "    img = rasterio.open(dfunet_path).read()\n",
    "    show(img.astype('uint8'), ax = ax[i][1], title=\"DFUNet_NoAttn_\"+os.path.basename(unet_path)[:-4])\n",
    "    \n",
    "    simpledfunet_path = os.path.join(path_to_simpledfunet_tiles, predicted_unet[i])\n",
    "    img = rasterio.open(simpledfunet_path).read()\n",
    "    show(img.astype('uint8'), ax = ax[i][2], title=\"Simple DFUNet_\"+os.path.basename(unet_path)[:-4])\n",
    "    \n",
    "    row, col = findRowCol(unet_path)\n",
    "    # gs_path = os.path.basename(pred_catalog.loc[pred_catalog['tile_col']==col, 'dir_gs'].iloc[0])\n",
    "    # img = rasterio.open(f\"dir_gs/{gs_path}\").read()\n",
    "    # show(img.astype('uint8'), ax = ax[i][3], title=\"GS\")\n",
    "    \n",
    "    os_path = os.path.basename(pred_catalog.loc[pred_catalog['tile_col']==col, 'dir_os'].iloc[0])\n",
    "    img = rasterio.open(f\"dir_os/{os_path}\")\n",
    "    os_images.append(img)\n",
    "    ax_curr = ax[i][3]\n",
    "    img_rescaled = rescale_image(img)\n",
    "    ax_curr.imshow(img_rescaled[:,:,(3,2,1)])\n",
    "\n",
    "pyplot.savefig(\"score_map_compare_simpledfunet.svg\",facecolor='white', format='svg',transparent=False, dpi=300)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
