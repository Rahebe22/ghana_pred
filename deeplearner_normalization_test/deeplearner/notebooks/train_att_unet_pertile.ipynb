{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Unet permutations \n",
    "\n",
    "Primarily focusing on variants of dropout and attention, as well as versions of original with fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Q4kB9xwMqE6s"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SC1iL8cfVqEr"
   },
   "outputs": [],
   "source": [
    "repo = \"deeplearner\"\n",
    "clone_path = \"/home/mappers/projects/\"\n",
    "repo_clone_path = f\"{clone_path}/{repo}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y4rXZmhHWGvs"
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(repo_clone_path, 'deeplearner/'))\n",
    "sys.path.insert(0, repo_clone_path)\n",
    "import deeplearner\n",
    "importlib.reload(deeplearner)\n",
    "from deeplearner.models import *\n",
    "from deeplearner.losses import *\n",
    "from deeplearner.datatorch2 import *\n",
    "from deeplearner.utils import *\n",
    "from deeplearner.compiler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lrh1bGe9WLUG"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"source_dir\" : \"/home/mappers/data/\",\n",
    "    \"working_dir\" : \"/home/mappers/tmp/gh_cg_tz_ng/attn_unet_dropout15\",\n",
    "    \n",
    "    # train and validation dataset\n",
    "    # \"train_csv_name\" : \"catalog_gh_cg_tz_ng_v1.csv\",\n",
    "    \"train_pickle_name\" : \"train_local_per_tile.pickle\",\n",
    "    \"val_pickle_name\" : \"val_local_per_tile.pickle\",\n",
    "    \"lbl_patchSize\" : 200,\n",
    "    \"one_side_buffer\" : 12,\n",
    "    \"tile_buffer\" : 11,\n",
    "    \"img_path_cols\" : [\"dir_os\"],\n",
    "    \"norm_stats_type\" : \"local_per_tile\",\n",
    "    \"label_path_col\" : \"dir_label\",\n",
    "    \"train_lbl_quality_groups\" : (0, 2, 3, 4),\n",
    "    \"val_lbl_quality_groups\" : (3, 4),\n",
    "    \"transformations\" : \n",
    "        ['vflip', 'hflip', 'rotate', 'resize', 'shift_brightness'],\n",
    "    \"rotationDegree\" : (-90, 90),\n",
    "    \"bshift_band_grouping\" : [4],\n",
    "\n",
    "    # train and validation DataLoader\n",
    "    \"train_BatchSize\" : 32,\n",
    "    \"val_BatchSize\" : 2,\n",
    "\n",
    "    # Model\n",
    "    \"input_channels\" : 4,\n",
    "    \"n_classes\" : 3,\n",
    "\n",
    "    # Model compiler\n",
    "    \"gpuDevices\" : [0],\n",
    "    \"params_init_path\" : None,\n",
    "    \"freeze_layer_ls\" : None,\n",
    "\n",
    "    # Model fitting\n",
    "    \"epochs\" : 200,\n",
    "    \"optimizer\": \"nesterov\",\n",
    "    \"LR\" : 0.01, \n",
    "    \"LR_policy\" : \"PolynomialLR\",\n",
    "    \"criterion\" : \"BalancedTverskyFocalLoss(gamma = 0.9)\",\n",
    "    \"momentum\" : 0.95,\n",
    "    \"resume\" : False,\n",
    "    \"resume_epoch\" : None,\n",
    "    \"bucket\" : \"activemapper\",\n",
    "    \"prefix_out\" : \"DL/models/gh_cg_tz_ng/attn_unet_dropout15\",\n",
    "    \"dropout_rate\" : 0.15\n",
    "\n",
    "    #prediction \n",
    "}\n",
    "\n",
    "pickle_dir = Path(config[\"source_dir\"]) / \"pickles\"\n",
    "if not os.path.exists(pickle_dir):\n",
    "    os.makedirs(pickle_dir)\n",
    "\n",
    "train_pickle_path = pickle_dir / config[\"train_pickle_name\"]\n",
    "val_pickle_path = pickle_dir / config[\"val_pickle_name\"]\n",
    "\n",
    "if not os.path.exists(config[\"working_dir\"]):\n",
    "    os.makedirs(config[\"working_dir\"])\n",
    "\n",
    "log_dir = Path(config[\"working_dir\"]) / \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZjX9goy8CeT",
    "tags": []
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEU3HjsOFBXk"
   },
   "source": [
    "**Step 1.** Setup seeding to make the experiment reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4rI6OmRsFRvq"
   },
   "outputs": [],
   "source": [
    "make_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_4skkAt8Srk"
   },
   "source": [
    "**Step 2.** Load the train and val datasets (i.e. divide the dataset into mini-batches after applying the augmentation, convert to tensor and put them on GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VIL29r0YXK-D"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(train_pickle_path)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"train_BatchSize\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-RzHFlbsXVoe"
   },
   "outputs": [],
   "source": [
    "validation_dataset = load_dataset(val_pickle_path)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=config[\"val_BatchSize\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzUV9cT79JF0"
   },
   "source": [
    "**Step 3.** Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M-AJ8_JDXZwx"
   },
   "outputs": [],
   "source": [
    "# model = eval('unet'.lower())(config[\"input_channels\"], config[\"n_classes\"])\n",
    "# model = unet_att_d(\n",
    "#     n_classes=config[\"n_classes\"], in_channels=config[\"input_channels\"], \n",
    "#     use_skipAtt=False, dropout_rate=config[\"dropout_rate\"]\n",
    "# )\n",
    "model = eval('unet_att_d'.lower())(\n",
    "    n_classes=config[\"n_classes\"], in_channels=config[\"input_channels\"], \n",
    "    use_skipAtt=False, dropout_rate=config[\"dropout_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_qltnA9bPp"
   },
   "source": [
    "**Step 4.** Compile\n",
    "\n",
    "The model Compiler is responsible for: \n",
    "1) handling the model parallelism on multiple GPUs, \n",
    "2) loading existing model parametrs if needed and\n",
    "3) freeze user-defined layers of model if model-based transfer learning is pursued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NJp_ZYL3Xhn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GPU available----------\n",
      "total number of trainable parameters: 157.9M\n",
      "---------- Vanilla Model compiled successfully ----------\n"
     ]
    }
   ],
   "source": [
    "model = ModelCompiler(\n",
    "    model, buffer = config[\"one_side_buffer\"], \n",
    "    gpuDevices = config[\"gpuDevices\"], \n",
    "    params_init = config[\"params_init_path\"],\n",
    "    freeze_params = config[\"freeze_layer_ls\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJXdlPWBbkM"
   },
   "source": [
    "**Step 5.** train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLzNotwQXnnH"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataloader, \n",
    "    validation_dataloader, \n",
    "    epochs = config[\"epochs\"], \n",
    "    optimizer_name = config[\"optimizer\"], \n",
    "    lr_init = config[\"LR\"], \n",
    "    lr_policy = config[\"LR_policy\"], \n",
    "    criterion = config[\"criterion\"], \n",
    "    momentum = config[\"momentum\"],\n",
    "    resume = config[\"resume\"], \n",
    "    resume_epoch = config[\"resume_epoch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dbXlGrWCOuC"
   },
   "source": [
    "**Step 6.** Save the trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "T9GklbduXw5j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss files uploaded to s3\n",
      "model parameters uploaded to s3!, at  DL/models/gh_cg_tz_ng/attn_unet_dropout15\n"
     ]
    }
   ],
   "source": [
    "model.save(bucket=config[\"bucket\"], outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOxDlWhJBxYS"
   },
   "source": [
    "**Step 7.** Evaluate the trained model against the evaluation dataset and report a number of accuracy metrics in a csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9C-XLAYwXvqX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start evaluation --------------------------\n",
      "-------------------------- Evaluation finished in 41s --------------------------\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validation_dataloader, bucket=config[\"bucket\"], \n",
    "               outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJU31PmpCiYr"
   },
   "source": [
    "**Step 8.** Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJI_yy7hX0nn"
   },
   "outputs": [],
   "source": [
    "def load_pred_data(dir_data, pred_patch_size, pred_buffer, pred_composite_buffer, \n",
    "                   pred_batch, catalog, catalog_row, img_path_cols, average_neighbors=False):\n",
    "    def load_single_tile(catalog_ind = catalog_row):\n",
    "        dataset = planetData(dir_data, catalog, pred_patch_size, pred_buffer, \n",
    "                             pred_composite_buffer, \"predict\", \n",
    "                             catalogIndex=catalog_ind, imgPathCols=img_path_cols)\n",
    "        data_loader = DataLoader(dataset, batch_size=pred_batch, shuffle=False)\n",
    "        meta = dataset.meta\n",
    "        tile = dataset.tile\n",
    "        return data_loader, meta, tile\n",
    "\n",
    "    if average_neighbors == True:\n",
    "        catalog[\"tile_col_row\"] = catalog.apply(lambda x: \"{}_{}\".format(x['tile_col'], x['tile_row']), axis=1)\n",
    "        tile_col = catalog.iloc[catalog_row].tile_col\n",
    "        tile_row = catalog.iloc[catalog_row].tile_row\n",
    "        row_dict = {\n",
    "            \"center\": catalog_row,\n",
    "            \"top\": catalog.query('tile_col=={} & tile_row=={}'.format(tile_col, tile_row - 1)).iloc[0].name \\\n",
    "                if \"{}_{}\".format(tile_col, tile_row - 1) in list(catalog.tile_col_row) else None,\n",
    "            \"left\" : catalog.query('tile_col=={} & tile_row=={}'.format(tile_col - 1, tile_row)).iloc[0].name \\\n",
    "                if \"{}_{}\".format(tile_col - 1, tile_row) in list(catalog.tile_col_row) else None,\n",
    "            \"right\" : catalog.query('tile_col=={} & tile_row=={}'.format(tile_col + 1, tile_row)).iloc[0].name \\\n",
    "                if \"{}_{}\".format(tile_col + 1, tile_row) in list(catalog.tile_col_row) else None,\n",
    "            \"bottom\": catalog.query('tile_col=={} & tile_row=={}'.format(tile_col, tile_row + 1)).iloc[0].name \\\n",
    "                if \"{}_{}\".format(tile_col, tile_row + 1) in list(catalog.tile_col_row) else None,\n",
    "            }\n",
    "        dataset_dict = {k:load_single_tile(catalog_ind = row_dict[k]) if row_dict[k] is not None else None \n",
    "                        for k in row_dict.keys()}\n",
    "        return dataset_dict\n",
    "    # direct crop edge pixels\n",
    "    else:\n",
    "        return load_single_tile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EU-l_ewFYiQY"
   },
   "outputs": [],
   "source": [
    "prefix_out = 'DL/predictions/gh_cg_tz/DFUNet_WithoutAttention_05032022/ghana'\n",
    "catalog = 'catalogs/predict/catalog_ghana_retiled_8.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB03NBvhYn8p"
   },
   "outputs": [],
   "source": [
    "pred_catalog = pd.read_csv(os.path.join(dir_data, catalog))\n",
    "inds = pred_catalog.query(\"type == 'center'\").index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBxfyK9OYsZK"
   },
   "outputs": [],
   "source": [
    "for i in inds:\n",
    "    print(\"Predicting on index %s\" % (i))\n",
    "    pred_dataloader = load_pred_data(\n",
    "        dir_data, pred_patch_size, pred_buffer, pred_composite_buffer, \n",
    "        pred_batch, pred_catalog, i, img_path_cols, \n",
    "        average_neighbors = average_neighbors\n",
    "    )\n",
    "    p = model.predict(\n",
    "        pred_dataloader, bucket, prefix_out, \n",
    "        pred_buffer, averageNeighbors=average_neighbors, \n",
    "        shrinkBuffer = shrink_pixels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLksaEmtY9jb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "fig, ax = pyplot.subplots(3,3, figsize=(15,20))\n",
    "for i in range(len(inds)):\n",
    "    col, row = pred_catalog.iloc[inds[i]][['tile_col', 'tile_row']]\n",
    "    image_path = 's3://{}/{}/Score_1/score_c{}_r{}.tif'.\\\n",
    "        format(bucket, prefix_out, col, row)\n",
    "    img = rasterio.open(image_path).read()\n",
    "    show(img.astype('uint8'), ax = ax[math.floor(i/3)][i%3], title=os.path.basename(image_path))\n",
    "    \n",
    "image_path\n",
    "pyplot.savefig(\"score_map_unet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukABIH0uZbG7"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "\n",
    "def findRowCol(filename):\n",
    "    col = re.findall(r\"(?<=_c)\\d\\d\\d(?=_r)\", filename)[0]\n",
    "    row = re.findall(r\"(?<=_r)\\d\\d\\d(?=.tif)\", filename)[0]\n",
    "    return int(row), int(col)\n",
    "\n",
    "def rescale_image(image, bands=(0, 1, 2, 3)):\n",
    "    img = reshape_as_image(image.read())[:,:,bands]\n",
    "    max_vals = [img[:, :, band].max() for band in range(img.shape[-1])]\n",
    "    img = img.astype('float64')\n",
    "    for band in bands:\n",
    "        band_vals = img[:, :, band]\n",
    "        img[:, :, band] = band_vals / max_vals[band]\n",
    "\n",
    "    return img\n",
    "\n",
    "path_to_unet_tiles = 'predicted_tiles_unet'\n",
    "path_to_dfunet_noattn_tiles = 'predicted_tiles_dfunet_noattn'\n",
    "path_to_simpledfunet_tiles = 'predicted_tiles_simpledfunet'\n",
    "\n",
    "predicted_unet = os.listdir(path_to_unet_tiles)\n",
    "predicted_dfunet = os.listdir(path_to_dfunet_noattn_tiles)\n",
    "predicted_simpledfunet = os.listdir(path_to_simpledfunet_tiles)\n",
    "\n",
    "assert(predicted_dfunet == predicted_unet == predicted_simpledfunet)\n",
    "n = len(predicted_unet)\n",
    "assert(len(os.listdir('dir_os')) == len(os.listdir('dir_gs')) == n)\n",
    "\n",
    "fig, ax = pyplot.subplots(n, 4, figsize=(18,40))\n",
    "\n",
    "os_images = []\n",
    "for i in range(n):\n",
    "    unet_path = os.path.join(path_to_unet_tiles, predicted_unet[i])\n",
    "    img = rasterio.open(unet_path).read()\n",
    "    show(img.astype('uint8'), ax = ax[i][0], title=\"UNet_\"+os.path.basename(unet_path)[:-4])\n",
    "    \n",
    "    dfunet_path = os.path.join(path_to_dfunet_noattn_tiles, predicted_unet[i])\n",
    "    img = rasterio.open(dfunet_path).read()\n",
    "    show(img.astype('uint8'), ax = ax[i][1], title=\"DFUNet_NoAttn_\"+os.path.basename(unet_path)[:-4])\n",
    "    \n",
    "    simpledfunet_path = os.path.join(path_to_simpledfunet_tiles, predicted_unet[i])\n",
    "    img = rasterio.open(simpledfunet_path).read()\n",
    "    show(img.astype('uint8'), ax = ax[i][2], title=\"Simple DFUNet_\"+os.path.basename(unet_path)[:-4])\n",
    "    \n",
    "    row, col = findRowCol(unet_path)\n",
    "    # gs_path = os.path.basename(pred_catalog.loc[pred_catalog['tile_col']==col, 'dir_gs'].iloc[0])\n",
    "    # img = rasterio.open(f\"dir_gs/{gs_path}\").read()\n",
    "    # show(img.astype('uint8'), ax = ax[i][3], title=\"GS\")\n",
    "    \n",
    "    os_path = os.path.basename(pred_catalog.loc[pred_catalog['tile_col']==col, 'dir_os'].iloc[0])\n",
    "    img = rasterio.open(f\"dir_os/{os_path}\")\n",
    "    os_images.append(img)\n",
    "    ax_curr = ax[i][3]\n",
    "    img_rescaled = rescale_image(img)\n",
    "    ax_curr.imshow(img_rescaled[:,:,(3,2,1)])\n",
    "\n",
    "pyplot.savefig(\"score_map_compare_simpledfunet.svg\",facecolor='white', format='svg',transparent=False, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout 0.15 with Skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lrh1bGe9WLUG"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"source_dir\" : \"/home/mappers/data/\",\n",
    "    \"working_dir\" : \"/home/mappers/tmp/gh_cg_tz_ng/attn_unet_dropout15_attn\",\n",
    "    \n",
    "    # train and validation dataset\n",
    "    # \"train_csv_name\" : \"catalog_gh_cg_tz_ng_v1.csv\",\n",
    "    \"train_pickle_name\" : \"train_local_per_tile.pickle\",\n",
    "    \"val_pickle_name\" : \"val_local_per_tile.pickle\",\n",
    "    \"lbl_patchSize\" : 200,\n",
    "    \"one_side_buffer\" : 12,\n",
    "    \"tile_buffer\" : 11,\n",
    "    \"img_path_cols\" : [\"dir_os\"],\n",
    "    \"norm_stats_type\" : \"local_per_tile\",\n",
    "    \"label_path_col\" : \"dir_label\",\n",
    "    \"train_lbl_quality_groups\" : (0, 2, 3, 4),\n",
    "    \"val_lbl_quality_groups\" : (3, 4),\n",
    "    \"transformations\" : \n",
    "        ['vflip', 'hflip', 'rotate', 'resize', 'shift_brightness'],\n",
    "    \"rotationDegree\" : (-90, 90),\n",
    "    \"bshift_band_grouping\" : [4],\n",
    "\n",
    "    # train and validation DataLoader\n",
    "    \"train_BatchSize\" : 32,\n",
    "    \"val_BatchSize\" : 2,\n",
    "\n",
    "    # Model\n",
    "    \"input_channels\" : 4,\n",
    "    \"n_classes\" : 3,\n",
    "\n",
    "    # Model compiler\n",
    "    \"gpuDevices\" : [0],\n",
    "    \"params_init_path\" : None,\n",
    "    \"freeze_layer_ls\" : None,\n",
    "\n",
    "    # Model fitting\n",
    "    \"epochs\" : 200,\n",
    "    \"optimizer\": \"nesterov\",\n",
    "    \"LR\" : 0.01, \n",
    "    \"LR_policy\" : \"PolynomialLR\",\n",
    "    \"criterion\" : \"BalancedTverskyFocalLoss(gamma = 0.9)\",\n",
    "    \"momentum\" : 0.95,\n",
    "    # \"resume\" : False,\n",
    "    \"resume\" : True, \n",
    "    # \"resume_epoch\" : None,\n",
    "    \"resume_epoch\" : 150,\n",
    "    \"bucket\" : \"activemapper\",\n",
    "    \"prefix_out\" : \"DL/models/gh_cg_tz_ng/attn_unet_dropout15_attn\",\n",
    "    \"dropout_rate\" : 0.15\n",
    "\n",
    "    #prediction \n",
    "}\n",
    "\n",
    "pickle_dir = Path(config[\"source_dir\"]) / \"pickles\"\n",
    "if not os.path.exists(pickle_dir):\n",
    "    os.makedirs(pickle_dir)\n",
    "\n",
    "train_pickle_path = pickle_dir / config[\"train_pickle_name\"]\n",
    "val_pickle_path = pickle_dir / config[\"val_pickle_name\"]\n",
    "\n",
    "if not os.path.exists(config[\"working_dir\"]):\n",
    "    os.makedirs(config[\"working_dir\"])\n",
    "\n",
    "log_dir = Path(config[\"working_dir\"]) / \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZjX9goy8CeT",
    "tags": []
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEU3HjsOFBXk"
   },
   "source": [
    "**Step 1.** Setup seeding to make the experiment reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4rI6OmRsFRvq"
   },
   "outputs": [],
   "source": [
    "make_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_4skkAt8Srk"
   },
   "source": [
    "**Step 2.** Load the train and val datasets (i.e. divide the dataset into mini-batches after applying the augmentation, convert to tensor and put them on GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VIL29r0YXK-D"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(train_pickle_path)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"train_BatchSize\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-RzHFlbsXVoe"
   },
   "outputs": [],
   "source": [
    "validation_dataset = load_dataset(val_pickle_path)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=config[\"val_BatchSize\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzUV9cT79JF0"
   },
   "source": [
    "**Step 3.** Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M-AJ8_JDXZwx"
   },
   "outputs": [],
   "source": [
    "model = eval('unet_att_d'.lower())(\n",
    "    n_classes=config[\"n_classes\"], in_channels=config[\"input_channels\"], \n",
    "    use_skipAtt=True, dropout_rate=config[\"dropout_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_qltnA9bPp"
   },
   "source": [
    "**Step 4.** Compile\n",
    "\n",
    "The model Compiler is responsible for: \n",
    "1) handling the model parallelism on multiple GPUs, \n",
    "2) loading existing model parametrs if needed and\n",
    "3) freeze user-defined layers of model if model-based transfer learning is pursued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NJp_ZYL3Xhn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GPU available----------\n",
      "total number of trainable parameters: 159.3M\n",
      "---------- Vanilla Model compiled successfully ----------\n"
     ]
    }
   ],
   "source": [
    "model = ModelCompiler(\n",
    "    model, buffer = config[\"one_side_buffer\"], \n",
    "    gpuDevices = config[\"gpuDevices\"], \n",
    "    params_init = config[\"params_init_path\"],\n",
    "    freeze_params = config[\"freeze_layer_ls\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJXdlPWBbkM"
   },
   "source": [
    "**Step 5.** train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLzNotwQXnnH"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataloader, \n",
    "    validation_dataloader, \n",
    "    epochs = config[\"epochs\"], \n",
    "    optimizer_name = config[\"optimizer\"], \n",
    "    lr_init = config[\"LR\"], \n",
    "    lr_policy = config[\"LR_policy\"], \n",
    "    criterion = config[\"criterion\"], \n",
    "    momentum = config[\"momentum\"],\n",
    "    resume = config[\"resume\"], \n",
    "    resume_epoch = config[\"resume_epoch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dbXlGrWCOuC"
   },
   "source": [
    "**Step 6.** Save the trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "T9GklbduXw5j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss files uploaded to s3\n",
      "model parameters uploaded to s3!, at  DL/models/gh_cg_tz_ng/attn_unet_dropout15_attn\n"
     ]
    }
   ],
   "source": [
    "model.save(bucket=config[\"bucket\"], outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOxDlWhJBxYS"
   },
   "source": [
    "**Step 7.** Evaluate the trained model against the evaluation dataset and report a number of accuracy metrics in a csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9C-XLAYwXvqX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start evaluation --------------------------\n",
      "-------------------------- Evaluation finished in 42s --------------------------\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validation_dataloader, bucket=config[\"bucket\"], \n",
    "               outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular U-Net warmup label group 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Lrh1bGe9WLUG"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"source_dir\" : \"/home/mappers/data/\",\n",
    "    \"working_dir\" : \"/home/mappers/tmp/gh_cg_tz_ng/unet_warmup_label_grp0\",\n",
    "    \n",
    "    # train and validation dataset\n",
    "    # \"train_csv_name\" : \"catalog_gh_cg_tz_ng_v1.csv\",\n",
    "    \"train_pickle_name\" : \"train_local_per_tile.pickle\",\n",
    "    \"val_pickle_name\" : \"val_local_per_tile.pickle\",\n",
    "    \"lbl_patchSize\" : 200,\n",
    "    \"one_side_buffer\" : 12,\n",
    "    \"tile_buffer\" : 11,\n",
    "    \"img_path_cols\" : [\"dir_os\"],\n",
    "    \"norm_stats_type\" : \"local_per_tile\",\n",
    "    \"label_path_col\" : \"dir_label\",\n",
    "    \"train_lbl_quality_groups\" : (0,),\n",
    "    \"val_lbl_quality_groups\" : (3, 4),\n",
    "    \"transformations\" : \n",
    "        ['vflip', 'hflip', 'rotate', 'resize', 'shift_brightness'],\n",
    "    \"rotationDegree\" : (-90, 90),\n",
    "    \"bshift_band_grouping\" : [4],\n",
    "\n",
    "    # train and validation DataLoader\n",
    "    \"train_BatchSize\" : 32,\n",
    "    \"val_BatchSize\" : 2,\n",
    "\n",
    "    # Model\n",
    "    \"input_channels\" : 4,\n",
    "    \"n_classes\" : 3,\n",
    "\n",
    "    # Model compiler\n",
    "    \"gpuDevices\" : [0],\n",
    "    \"params_init_path\" : None,\n",
    "    \"freeze_layer_ls\" : None,\n",
    "\n",
    "    # Model fitting\n",
    "    \"epochs\" : 150,\n",
    "    \"optimizer\": \"nesterov\",\n",
    "    \"LR\" : 0.01, \n",
    "    \"LR_policy\" : \"PolynomialLR\",\n",
    "    \"criterion\" : \"BalancedTverskyFocalLoss(gamma = 0.9)\",\n",
    "    \"momentum\" : 0.95,\n",
    "    \"resume\" : False,\n",
    "    \"resume_epoch\" : None,\n",
    "    \"bucket\" : \"activemapper\",\n",
    "    \"prefix_out\" : \"DL/models/gh_cg_tz_ng/unet_warmup_label_grp0\",\n",
    "    \"dropout_rate\" : 0\n",
    "\n",
    "    #prediction \n",
    "}\n",
    "\n",
    "pickle_dir = Path(config[\"source_dir\"]) / \"pickles\"\n",
    "if not os.path.exists(pickle_dir):\n",
    "    os.makedirs(pickle_dir)\n",
    "\n",
    "train_pickle_path = pickle_dir / config[\"train_pickle_name\"]\n",
    "val_pickle_path = pickle_dir / config[\"val_pickle_name\"]\n",
    "\n",
    "if not os.path.exists(config[\"working_dir\"]):\n",
    "    os.makedirs(config[\"working_dir\"])\n",
    "\n",
    "log_dir = Path(config[\"working_dir\"]) / \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZjX9goy8CeT",
    "tags": []
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEU3HjsOFBXk"
   },
   "source": [
    "**Step 1.** Setup seeding to make the experiment reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4rI6OmRsFRvq"
   },
   "outputs": [],
   "source": [
    "make_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_4skkAt8Srk"
   },
   "source": [
    "**Step 2.** Load the train and val datasets (i.e. divide the dataset into mini-batches after applying the augmentation, convert to tensor and put them on GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VIL29r0YXK-D"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(train_pickle_path)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"train_BatchSize\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-RzHFlbsXVoe"
   },
   "outputs": [],
   "source": [
    "validation_dataset = load_dataset(val_pickle_path)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=config[\"val_BatchSize\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzUV9cT79JF0"
   },
   "source": [
    "**Step 3.** Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M-AJ8_JDXZwx"
   },
   "outputs": [],
   "source": [
    "model = eval('unet_att_d'.lower())(\n",
    "    n_classes=config[\"n_classes\"], in_channels=config[\"input_channels\"], \n",
    "    use_skipAtt=False, dropout_rate=config[\"dropout_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_qltnA9bPp"
   },
   "source": [
    "**Step 4.** Compile\n",
    "\n",
    "The model Compiler is responsible for: \n",
    "1) handling the model parallelism on multiple GPUs, \n",
    "2) loading existing model parametrs if needed and\n",
    "3) freeze user-defined layers of model if model-based transfer learning is pursued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NJp_ZYL3Xhn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GPU available----------\n",
      "total number of trainable parameters: 157.9M\n",
      "---------- Vanilla Model compiled successfully ----------\n"
     ]
    }
   ],
   "source": [
    "model = ModelCompiler(\n",
    "    model, buffer = config[\"one_side_buffer\"], \n",
    "    gpuDevices = config[\"gpuDevices\"], \n",
    "    params_init = config[\"params_init_path\"],\n",
    "    freeze_params = config[\"freeze_layer_ls\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJXdlPWBbkM"
   },
   "source": [
    "**Step 5.** train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLzNotwQXnnH"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataloader, \n",
    "    validation_dataloader, \n",
    "    epochs = config[\"epochs\"], \n",
    "    optimizer_name = config[\"optimizer\"], \n",
    "    lr_init = config[\"LR\"], \n",
    "    lr_policy = config[\"LR_policy\"], \n",
    "    criterion = config[\"criterion\"], \n",
    "    momentum = config[\"momentum\"],\n",
    "    resume = config[\"resume\"], \n",
    "    resume_epoch = config[\"resume_epoch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dbXlGrWCOuC"
   },
   "source": [
    "**Step 6.** Save the trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "T9GklbduXw5j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss files uploaded to s3\n",
      "model parameters uploaded to s3!, at  DL/models/gh_cg_tz_ng/unet_warmup_label_grp0\n"
     ]
    }
   ],
   "source": [
    "model.save(bucket=config[\"bucket\"], outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOxDlWhJBxYS"
   },
   "source": [
    "**Step 7.** Evaluate the trained model against the evaluation dataset and report a number of accuracy metrics in a csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9C-XLAYwXvqX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start evaluation --------------------------\n",
      "-------------------------- Evaluation finished in 36s --------------------------\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validation_dataloader, bucket=config[\"bucket\"], \n",
    "               outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune regular U-Net label group 3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lrh1bGe9WLUG"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"source_dir\" : \"/home/mappers/data/\",\n",
    "    \"working_dir\" : \"/home/mappers/tmp/gh_cg_tz_ng/unet_finetune_label_grp34\",\n",
    "    \n",
    "    # train and validation dataset\n",
    "    # \"train_csv_name\" : \"catalog_gh_cg_tz_ng_v1.csv\",\n",
    "    \"train_pickle_name\" : \"refine_ghana_per_tile.pickle\",\n",
    "    \"val_pickle_name\" : \"val_ghana_per_tile.pickle\",\n",
    "    \"lbl_patchSize\" : 200,\n",
    "    \"one_side_buffer\" : 12,\n",
    "    \"tile_buffer\" : 11,\n",
    "    \"img_path_cols\" : [\"dir_os\"],\n",
    "    \"norm_stats_type\" : \"local_per_tile\",\n",
    "    \"label_path_col\" : \"dir_label\",\n",
    "    \"train_lbl_quality_groups\" : (2, 3, 4),\n",
    "    \"val_lbl_quality_groups\" : (3, 4),\n",
    "    \"transformations\" : \n",
    "        ['vflip', 'hflip', 'rotate', 'resize', 'shift_brightness'],\n",
    "    \"rotationDegree\" : (-90, 90),\n",
    "    \"bshift_band_grouping\" : [4],\n",
    "\n",
    "    # train and validation DataLoader\n",
    "    \"train_BatchSize\" : 32,\n",
    "    \"val_BatchSize\" : 2,\n",
    "\n",
    "    # Model\n",
    "    \"input_channels\" : 4,\n",
    "    \"n_classes\" : 3,\n",
    "\n",
    "    # Model compiler\n",
    "    \"gpuDevices\" : [0],\n",
    "    \"params_init_path\" : \n",
    "        (\n",
    "            f\"s3://activemapper/DL/models/gh_cg_tz_ng/unet_warmup_label_grp0/\"\n",
    "            f\"unet_att_d_params.pth\"\n",
    "        ),\n",
    "    \"freeze_layer_ls\" : list(range(58)),\n",
    "\n",
    "    # Model fitting\n",
    "    \"epochs\" : 25,\n",
    "    \"optimizer\": \"nesterov\",\n",
    "    \"LR\" : 0.005, \n",
    "    \"LR_policy\" : \"PolynomialLR\",\n",
    "    \"criterion\" : \"BalancedTverskyFocalLoss(gamma = 0.9)\",\n",
    "    \"momentum\" : 0.95,\n",
    "    \"resume\" : False,\n",
    "    \"resume_epoch\" : None,\n",
    "    \"bucket\" : \"activemapper\",\n",
    "    \"prefix_out\" : \"DL/models/gh_cg_tz_ng/unet_finetune_label_grp34\",\n",
    "    \"dropout_rate\" : 0\n",
    "\n",
    "    #prediction \n",
    "}\n",
    "\n",
    "pickle_dir = Path(config[\"source_dir\"]) / \"pickles\"\n",
    "if not os.path.exists(pickle_dir):\n",
    "    os.makedirs(pickle_dir)\n",
    "\n",
    "train_pickle_path = pickle_dir / config[\"train_pickle_name\"]\n",
    "val_pickle_path = pickle_dir / config[\"val_pickle_name\"]\n",
    "\n",
    "if not os.path.exists(config[\"working_dir\"]):\n",
    "    os.makedirs(config[\"working_dir\"])\n",
    "\n",
    "log_dir = Path(config[\"working_dir\"]) / \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZjX9goy8CeT",
    "tags": []
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEU3HjsOFBXk"
   },
   "source": [
    "**Step 1.** Setup seeding to make the experiment reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4rI6OmRsFRvq"
   },
   "outputs": [],
   "source": [
    "make_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_4skkAt8Srk"
   },
   "source": [
    "**Step 2.** Load the train and val datasets (i.e. divide the dataset into mini-batches after applying the augmentation, convert to tensor and put them on GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VIL29r0YXK-D"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(train_pickle_path)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"train_BatchSize\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-RzHFlbsXVoe"
   },
   "outputs": [],
   "source": [
    "validation_dataset = load_dataset(val_pickle_path)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=config[\"val_BatchSize\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzUV9cT79JF0"
   },
   "source": [
    "**Step 3.** Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M-AJ8_JDXZwx"
   },
   "outputs": [],
   "source": [
    "model = eval('unet_att_d'.lower())(\n",
    "    n_classes=config[\"n_classes\"], in_channels=config[\"input_channels\"], \n",
    "    use_skipAtt=False, dropout_rate=config[\"dropout_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_qltnA9bPp"
   },
   "source": [
    "**Step 4.** Compile\n",
    "\n",
    "The model Compiler is responsible for: \n",
    "1) handling the model parallelism on multiple GPUs, \n",
    "2) loading existing model parametrs if needed and\n",
    "3) freeze user-defined layers of model if model-based transfer learning is pursued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NJp_ZYL3Xhn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GPU available----------\n",
      "total number of trainable parameters: 1.2M\n",
      "---------- Pre-trained model compiled successfully ----------\n"
     ]
    }
   ],
   "source": [
    "model = ModelCompiler(\n",
    "    model, buffer = config[\"one_side_buffer\"], \n",
    "    gpuDevices = config[\"gpuDevices\"], \n",
    "    params_init = config[\"params_init_path\"],\n",
    "    freeze_params = config[\"freeze_layer_ls\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJXdlPWBbkM"
   },
   "source": [
    "**Step 5.** train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLzNotwQXnnH"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataloader, \n",
    "    validation_dataloader, \n",
    "    epochs = config[\"epochs\"], \n",
    "    optimizer_name = config[\"optimizer\"], \n",
    "    lr_init = config[\"LR\"], \n",
    "    lr_policy = config[\"LR_policy\"], \n",
    "    criterion = config[\"criterion\"], \n",
    "    momentum = config[\"momentum\"],\n",
    "    resume = config[\"resume\"], \n",
    "    resume_epoch = config[\"resume_epoch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dbXlGrWCOuC"
   },
   "source": [
    "**Step 6.** Save the trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "T9GklbduXw5j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss files uploaded to s3\n",
      "model parameters uploaded to s3!, at  DL/models/gh_cg_tz_ng/unet_finetune_label_grp34\n"
     ]
    }
   ],
   "source": [
    "model.save(bucket=config[\"bucket\"], outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOxDlWhJBxYS"
   },
   "source": [
    "**Step 7.** Evaluate the trained model against the evaluation dataset and report a number of accuracy metrics in a csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9C-XLAYwXvqX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start evaluation --------------------------\n",
      "-------------------------- Evaluation finished in 18s --------------------------\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validation_dataloader, bucket=config[\"bucket\"], \n",
    "               outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lrh1bGe9WLUG"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"source_dir\" : \"/home/mappers/data/\",\n",
    "    \"working_dir\" : \"/home/mappers/tmp/gh_cg_tz_ng/attn_unet_dropout30\",\n",
    "    \n",
    "    # train and validation dataset\n",
    "    \"train_pickle_name\" : \"train_local_per_tile.pickle\",\n",
    "    \"val_pickle_name\" : \"val_local_per_tile.pickle\",\n",
    "    \"lbl_patchSize\" : 200,\n",
    "    \"one_side_buffer\" : 12,\n",
    "    \"tile_buffer\" : 11,\n",
    "    \"img_path_cols\" : [\"dir_os\"],\n",
    "    \"norm_stats_type\" : \"local_per_tile\",\n",
    "    \"label_path_col\" : \"dir_label\",\n",
    "    \"train_lbl_quality_groups\" : (0, 2, 3, 4),\n",
    "    \"val_lbl_quality_groups\" : (3, 4),\n",
    "    \"transformations\" : \n",
    "        ['vflip', 'hflip', 'rotate', 'resize', 'shift_brightness'],\n",
    "    \"rotationDegree\" : (-90, 90),\n",
    "    \"bshift_band_grouping\" : [4],\n",
    "\n",
    "    # train and validation DataLoader\n",
    "    \"train_BatchSize\" : 32,\n",
    "    \"val_BatchSize\" : 2,\n",
    "\n",
    "    # Model\n",
    "    \"input_channels\" : 4,\n",
    "    \"n_classes\" : 3,\n",
    "\n",
    "    # Model compiler\n",
    "    \"gpuDevices\" : [0],\n",
    "    \"params_init_path\" : None,\n",
    "    \"freeze_layer_ls\" : None,\n",
    "\n",
    "    # Model fitting\n",
    "    \"epochs\" : 120,\n",
    "    \"optimizer\": \"nesterov\",\n",
    "    \"LR\" : 0.01, \n",
    "    \"LR_policy\" : \"PolynomialLR\",\n",
    "    \"criterion\" : \"BalancedTverskyFocalLoss(gamma = 0.9)\",\n",
    "    \"momentum\" : 0.95,\n",
    "    \"resume\" : False,\n",
    "    \"resume_epoch\" : None,\n",
    "    \"bucket\" : \"activemapper\",\n",
    "    \"prefix_out\" : \"DL/models/gh_cg_tz_ng/attn_unet_dropout30\",\n",
    "    \"dropout_rate\" : 0.30\n",
    "\n",
    "    #prediction \n",
    "}\n",
    "\n",
    "pickle_dir = Path(config[\"source_dir\"]) / \"pickles\"\n",
    "if not os.path.exists(pickle_dir):\n",
    "    os.makedirs(pickle_dir)\n",
    "\n",
    "train_pickle_path = pickle_dir / config[\"train_pickle_name\"]\n",
    "val_pickle_path = pickle_dir / config[\"val_pickle_name\"]\n",
    "\n",
    "if not os.path.exists(config[\"working_dir\"]):\n",
    "    os.makedirs(config[\"working_dir\"])\n",
    "\n",
    "log_dir = Path(config[\"working_dir\"]) / \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZjX9goy8CeT",
    "tags": []
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEU3HjsOFBXk"
   },
   "source": [
    "**Step 1.** Setup seeding to make the experiment reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4rI6OmRsFRvq"
   },
   "outputs": [],
   "source": [
    "make_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_4skkAt8Srk"
   },
   "source": [
    "**Step 2.** Load the train and val datasets (i.e. divide the dataset into mini-batches after applying the augmentation, convert to tensor and put them on GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VIL29r0YXK-D"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(train_pickle_path)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"train_BatchSize\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-RzHFlbsXVoe"
   },
   "outputs": [],
   "source": [
    "validation_dataset = load_dataset(val_pickle_path)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=config[\"val_BatchSize\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzUV9cT79JF0"
   },
   "source": [
    "**Step 3.** Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M-AJ8_JDXZwx"
   },
   "outputs": [],
   "source": [
    "model = eval('unet_att_d'.lower())(\n",
    "    n_classes=config[\"n_classes\"], in_channels=config[\"input_channels\"], \n",
    "    use_skipAtt=False, dropout_rate=config[\"dropout_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_qltnA9bPp"
   },
   "source": [
    "**Step 4.** Compile\n",
    "\n",
    "The model Compiler is responsible for: \n",
    "1) handling the model parallelism on multiple GPUs, \n",
    "2) loading existing model parametrs if needed and\n",
    "3) freeze user-defined layers of model if model-based transfer learning is pursued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NJp_ZYL3Xhn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GPU available----------\n",
      "total number of trainable parameters: 157.9M\n",
      "---------- Vanilla Model compiled successfully ----------\n"
     ]
    }
   ],
   "source": [
    "model = ModelCompiler(\n",
    "    model, buffer = config[\"one_side_buffer\"], \n",
    "    gpuDevices = config[\"gpuDevices\"], \n",
    "    params_init = config[\"params_init_path\"],\n",
    "    freeze_params = config[\"freeze_layer_ls\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJXdlPWBbkM"
   },
   "source": [
    "**Step 5.** train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLzNotwQXnnH"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataloader, \n",
    "    validation_dataloader, \n",
    "    epochs = config[\"epochs\"], \n",
    "    optimizer_name = config[\"optimizer\"], \n",
    "    lr_init = config[\"LR\"], \n",
    "    lr_policy = config[\"LR_policy\"], \n",
    "    criterion = config[\"criterion\"], \n",
    "    momentum = config[\"momentum\"],\n",
    "    resume = config[\"resume\"], \n",
    "    resume_epoch = config[\"resume_epoch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dbXlGrWCOuC"
   },
   "source": [
    "**Step 6.** Save the trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "T9GklbduXw5j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss files uploaded to s3\n",
      "model parameters uploaded to s3!, at  DL/models/gh_cg_tz_ng/attn_unet_dropout30\n"
     ]
    }
   ],
   "source": [
    "model.save(bucket=config[\"bucket\"], outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOxDlWhJBxYS"
   },
   "source": [
    "**Step 7.** Evaluate the trained model against the evaluation dataset and report a number of accuracy metrics in a csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9C-XLAYwXvqX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start evaluation --------------------------\n",
      "-------------------------- Evaluation finished in 40s --------------------------\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validation_dataloader, bucket=config[\"bucket\"], \n",
    "               outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lrh1bGe9WLUG"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"source_dir\" : \"/home/mappers/data/\",\n",
    "    \"working_dir\" : \"/home/mappers/tmp/gh_cg_tz_ng/attn_unet_dropout10\",\n",
    "    \n",
    "    # train and validation dataset\n",
    "    \"train_pickle_name\" : \"train_local_per_tile.pickle\",\n",
    "    \"val_pickle_name\" : \"val_local_per_tile.pickle\",\n",
    "    \"lbl_patchSize\" : 200,\n",
    "    \"one_side_buffer\" : 12,\n",
    "    \"tile_buffer\" : 11,\n",
    "    \"img_path_cols\" : [\"dir_os\"],\n",
    "    \"norm_stats_type\" : \"local_per_tile\",\n",
    "    \"label_path_col\" : \"dir_label\",\n",
    "    \"train_lbl_quality_groups\" : (0, 2, 3, 4),\n",
    "    \"val_lbl_quality_groups\" : (3, 4),\n",
    "    \"transformations\" : \n",
    "        ['vflip', 'hflip', 'rotate', 'resize', 'shift_brightness'],\n",
    "    \"rotationDegree\" : (-90, 90),\n",
    "    \"bshift_band_grouping\" : [4],\n",
    "\n",
    "    # train and validation DataLoader\n",
    "    \"train_BatchSize\" : 32,\n",
    "    \"val_BatchSize\" : 2,\n",
    "\n",
    "    # Model\n",
    "    \"input_channels\" : 4,\n",
    "    \"n_classes\" : 3,\n",
    "\n",
    "    # Model compiler\n",
    "    \"gpuDevices\" : [0],\n",
    "    \"params_init_path\" : None,\n",
    "    \"freeze_layer_ls\" : None,\n",
    "\n",
    "    # Model fitting\n",
    "    \"epochs\" : 120,\n",
    "    \"optimizer\": \"nesterov\",\n",
    "    \"LR\" : 0.01, \n",
    "    \"LR_policy\" : \"PolynomialLR\",\n",
    "    \"criterion\" : \"BalancedTverskyFocalLoss(gamma = 0.9)\",\n",
    "    \"momentum\" : 0.95,\n",
    "    \"resume\" : False,\n",
    "    \"resume_epoch\" : None,\n",
    "    \"bucket\" : \"activemapper\",\n",
    "    \"prefix_out\" : \"DL/models/gh_cg_tz_ng/attn_unet_dropout10\",\n",
    "    \"dropout_rate\" : 0.10\n",
    "\n",
    "    #prediction \n",
    "}\n",
    "\n",
    "pickle_dir = Path(config[\"source_dir\"]) / \"pickles\"\n",
    "if not os.path.exists(pickle_dir):\n",
    "    os.makedirs(pickle_dir)\n",
    "\n",
    "train_pickle_path = pickle_dir / config[\"train_pickle_name\"]\n",
    "val_pickle_path = pickle_dir / config[\"val_pickle_name\"]\n",
    "\n",
    "if not os.path.exists(config[\"working_dir\"]):\n",
    "    os.makedirs(config[\"working_dir\"])\n",
    "\n",
    "log_dir = Path(config[\"working_dir\"]) / \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZjX9goy8CeT",
    "tags": []
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEU3HjsOFBXk"
   },
   "source": [
    "**Step 1.** Setup seeding to make the experiment reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4rI6OmRsFRvq"
   },
   "outputs": [],
   "source": [
    "make_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_4skkAt8Srk"
   },
   "source": [
    "**Step 2.** Load the train and val datasets (i.e. divide the dataset into mini-batches after applying the augmentation, convert to tensor and put them on GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VIL29r0YXK-D"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(train_pickle_path)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"train_BatchSize\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-RzHFlbsXVoe"
   },
   "outputs": [],
   "source": [
    "validation_dataset = load_dataset(val_pickle_path)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=config[\"val_BatchSize\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzUV9cT79JF0"
   },
   "source": [
    "**Step 3.** Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M-AJ8_JDXZwx"
   },
   "outputs": [],
   "source": [
    "model = eval('unet_att_d'.lower())(\n",
    "    n_classes=config[\"n_classes\"], in_channels=config[\"input_channels\"], \n",
    "    use_skipAtt=False, dropout_rate=config[\"dropout_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_qltnA9bPp"
   },
   "source": [
    "**Step 4.** Compile\n",
    "\n",
    "The model Compiler is responsible for: \n",
    "1) handling the model parallelism on multiple GPUs, \n",
    "2) loading existing model parametrs if needed and\n",
    "3) freeze user-defined layers of model if model-based transfer learning is pursued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NJp_ZYL3Xhn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GPU available----------\n",
      "total number of trainable parameters: 157.9M\n",
      "---------- Vanilla Model compiled successfully ----------\n"
     ]
    }
   ],
   "source": [
    "model = ModelCompiler(\n",
    "    model, buffer = config[\"one_side_buffer\"], \n",
    "    gpuDevices = config[\"gpuDevices\"], \n",
    "    params_init = config[\"params_init_path\"],\n",
    "    freeze_params = config[\"freeze_layer_ls\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJXdlPWBbkM"
   },
   "source": [
    "**Step 5.** train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dLzNotwQXnnH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start training --------------------------\n",
      "[1/120]\n",
      "train loss:0.8990954113006592\n",
      "validation loss: 0.8357470256789606\n",
      "LR: 0.009919999758550428\n",
      "time: 184\n",
      "[2/120]\n",
      "train loss:0.8715323309103647\n",
      "validation loss: 0.8925246170588902\n",
      "LR: 0.009919999758550428\n",
      "time: 182\n",
      "[3/120]\n",
      "train loss:0.8529868717988333\n",
      "validation loss: 0.7869662196346919\n",
      "LR: 0.009839837734062955\n",
      "time: 181\n",
      "[4/120]\n",
      "train loss:0.8432920571168264\n",
      "validation loss: 0.7947814690509849\n",
      "LR: 0.009759511943429413\n",
      "time: 182\n",
      "[5/120]\n",
      "train loss:0.8370611317952474\n",
      "validation loss: 0.749155959494564\n",
      "LR: 0.009679020358515226\n",
      "time: 182\n",
      "[6/120]\n",
      "train loss:0.8294369085629781\n",
      "validation loss: 0.7263271165025724\n",
      "LR: 0.009598360904656872\n",
      "time: 181\n",
      "[7/120]\n",
      "train loss:0.8228398784001668\n",
      "validation loss: 0.7037473516918871\n",
      "LR: 0.009517531459092827\n",
      "time: 181\n",
      "[8/120]\n",
      "train loss:0.8197426251570383\n",
      "validation loss: 0.7724621781737221\n",
      "LR: 0.009436529849324329\n",
      "time: 182\n",
      "[9/120]\n",
      "train loss:0.8134750092029571\n",
      "validation loss: 0.7247624273640009\n",
      "LR: 0.00935535385140202\n",
      "time: 181\n",
      "[10/120]\n",
      "train loss:0.811564699014028\n",
      "validation loss: 0.6922832130720573\n",
      "LR: 0.009274001188134292\n",
      "time: 180\n",
      "[11/120]\n",
      "train loss:0.8068794667720794\n",
      "validation loss: 0.6761681180095718\n",
      "LR: 0.009192469527212815\n",
      "time: 181\n",
      "[12/120]\n",
      "train loss:0.8051110422611236\n",
      "validation loss: 0.7172248068227604\n",
      "LR: 0.00911075647925052\n",
      "time: 180\n",
      "[13/120]\n",
      "train loss:0.8034525163968405\n",
      "validation loss: 0.6762000632291774\n",
      "LR: 0.00902885959572685\n",
      "time: 180\n",
      "[14/120]\n",
      "train loss:0.8027471454938253\n",
      "validation loss: 0.6689962416279073\n",
      "LR: 0.008946776366834828\n",
      "time: 180\n",
      "[15/120]\n",
      "train loss:0.7979770044485728\n",
      "validation loss: 0.7175910144816248\n",
      "LR: 0.008864504219224079\n",
      "time: 183\n",
      "[16/120]\n",
      "train loss:0.7978225529193879\n",
      "validation loss: 0.6600771564800216\n",
      "LR: 0.008782040513633455\n",
      "time: 179\n",
      "[17/120]\n",
      "train loss:0.7943791822592418\n",
      "validation loss: 0.6624663132100309\n",
      "LR: 0.008699382542406575\n",
      "time: 179\n",
      "[18/120]\n",
      "train loss:0.7924413386980692\n",
      "validation loss: 0.6450035663853798\n",
      "LR: 0.008616527526882934\n",
      "time: 179\n",
      "[19/120]\n",
      "train loss:0.7930129726727804\n",
      "validation loss: 0.6496749442636168\n",
      "LR: 0.008533472614656866\n",
      "time: 181\n",
      "[20/120]\n",
      "train loss:0.7926847791671753\n",
      "validation loss: 0.7022805233552519\n",
      "LR: 0.008450214876695889\n",
      "time: 180\n",
      "[21/120]\n",
      "train loss:0.7925290854771933\n",
      "validation loss: 0.6740982332192623\n",
      "LR: 0.008366751304309457\n",
      "time: 180\n",
      "[22/120]\n",
      "train loss:0.7880224764347077\n",
      "validation loss: 0.6533409619124189\n",
      "LR: 0.008283078805958329\n",
      "time: 180\n",
      "[23/120]\n",
      "train loss:0.7890295958518982\n",
      "validation loss: 0.6566153472260933\n",
      "LR: 0.0081991942038941\n",
      "time: 181\n",
      "[24/120]\n",
      "train loss:0.7855234440167745\n",
      "validation loss: 0.6425557938827278\n",
      "LR: 0.0081150942306175\n",
      "time: 179\n",
      "[25/120]\n",
      "train loss:0.7856507448355357\n",
      "validation loss: 0.6305580149150491\n",
      "LR: 0.007861467982358478\n",
      "time: 180\n",
      "[28/120]\n",
      "train loss:0.7861549444993337\n",
      "validation loss: 0.6471404975270663\n",
      "LR: 0.00777647191904972\n",
      "time: 180\n",
      "[29/120]\n",
      "train loss:0.7839319837093354\n",
      "validation loss: 0.6351283604032075\n",
      "LR: 0.007691242662494246\n",
      "time: 179\n",
      "[30/120]\n",
      "train loss:0.781704982916514\n",
      "validation loss: 0.6343040618289985\n",
      "LR: 0.007605776320486014\n",
      "time: 180\n",
      "[31/120]\n",
      "train loss:0.7826941684881846\n",
      "validation loss: 0.6475827155006059\n",
      "LR: 0.007520068880033955\n",
      "time: 180\n",
      "[32/120]\n",
      "train loss:0.7833586752414703\n",
      "validation loss: 0.6420436200129856\n",
      "LR: 0.0074341162018317685\n",
      "time: 180\n",
      "[33/120]\n",
      "train loss:0.7843271430333455\n",
      "validation loss: 0.6415727601339981\n",
      "LR: 0.0073479140143905665\n",
      "time: 181\n",
      "[34/120]\n",
      "train loss:0.7820173136393229\n",
      "validation loss: 0.631767339334759\n",
      "LR: 0.00726145790780852\n",
      "time: 180\n",
      "[35/120]\n",
      "train loss:0.7816246191660563\n",
      "validation loss: 0.6352015686597394\n",
      "LR: 0.007174743327149298\n",
      "time: 180\n",
      "[36/120]\n",
      "train loss:0.7796055769920349\n",
      "validation loss: 0.6366852702819731\n",
      "LR: 0.0070877655653984305\n",
      "time: 179\n",
      "[37/120]\n",
      "train loss:0.7814145354429881\n",
      "validation loss: 0.6374505312037678\n",
      "LR: 0.007000519755963742\n",
      "time: 180\n",
      "[38/120]\n",
      "train loss:0.7796515985329946\n",
      "validation loss: 0.6300980602723679\n",
      "LR: 0.006913000864682789\n",
      "time: 180\n",
      "[39/120]\n",
      "train loss:0.7780858198801677\n",
      "validation loss: 0.6273594806313797\n",
      "LR: 0.006825203681296486\n",
      "time: 180\n",
      "[40/120]\n",
      "train loss:0.7803091009457906\n",
      "validation loss: 0.6201292356804051\n",
      "LR: 0.006737122810344113\n",
      "time: 179\n",
      "[41/120]\n",
      "train loss:0.7786061588923137\n",
      "validation loss: 0.6307968079703902\n",
      "LR: 0.00664875266143025\n",
      "time: 180\n",
      "[42/120]\n",
      "train loss:0.7792475501696269\n",
      "validation loss: 0.6249321890881758\n",
      "LR: 0.006560087438809122\n",
      "time: 180\n",
      "[43/120]\n",
      "train loss:0.7780495429039002\n",
      "validation loss: 0.6263457504613384\n",
      "LR: 0.006471121130226067\n",
      "time: 181\n",
      "[44/120]\n",
      "train loss:0.7765490206082662\n",
      "validation loss: 0.6256773784327231\n",
      "LR: 0.0063818474949494065\n",
      "time: 181\n",
      "[45/120]\n",
      "train loss:0.7784862033526103\n",
      "validation loss: 0.6179007168500494\n",
      "LR: 0.00629226005091868\n",
      "time: 181\n",
      "[46/120]\n",
      "train loss:0.774307107925415\n",
      "validation loss: 0.6243153831969628\n",
      "LR: 0.006202352060927052\n",
      "time: 181\n",
      "[47/120]\n",
      "train loss:0.7767150795459747\n",
      "validation loss: 0.6262207841132388\n",
      "LR: 0.00611211651774637\n",
      "time: 182\n",
      "[48/120]\n",
      "train loss:0.7759600551923116\n",
      "validation loss: 0.6218006994076488\n",
      "LR: 0.006021546128092842\n",
      "time: 181\n",
      "[49/120]\n",
      "train loss:0.7762319461504619\n",
      "validation loss: 0.6203886539430585\n",
      "LR: 0.005930633295319308\n",
      "time: 180\n",
      "[50/120]\n",
      "train loss:0.7750452276070913\n",
      "validation loss: 0.6211319957140831\n",
      "LR: 0.005839370100706513\n",
      "time: 180\n",
      "[51/120]\n",
      "train loss:0.7750223569075266\n",
      "validation loss: 0.6179999040182245\n",
      "LR: 0.005747748283210189\n",
      "time: 182\n",
      "[52/120]\n",
      "train loss:0.7761009061336517\n",
      "validation loss: 0.6139675563381574\n",
      "LR: 0.0056557592175029495\n",
      "time: 182\n",
      "[53/120]\n",
      "train loss:0.775002252260844\n",
      "validation loss: 0.6116428036178576\n",
      "LR: 0.005563393890129641\n",
      "time: 180\n",
      "[54/120]\n",
      "train loss:0.7751618429025015\n",
      "validation loss: 0.6226806014756036\n",
      "LR: 0.005470642873571245\n",
      "time: 181\n",
      "[55/120]\n",
      "train loss:0.7587934954961141\n",
      "validation loss: 0.6009566016695019\n",
      "LR: 1e-05\n",
      "time: 181\n",
      "[107/120]\n",
      "train loss:0.75801509141922\n",
      "validation loss: 0.6008044586356771\n",
      "LR: 1e-05\n",
      "time: 180\n",
      "[108/120]\n",
      "train loss:0.7599895044167837\n",
      "validation loss: 0.6014450149321011\n",
      "LR: 1e-05\n",
      "time: 180\n",
      "[109/120]\n",
      "train loss:0.7588125614325205\n",
      "validation loss: 0.6005900488793746\n",
      "LR: 1e-05\n",
      "time: 181\n",
      "[110/120]\n",
      "train loss:0.7596977682908376\n",
      "validation loss: 0.6004456993096585\n",
      "LR: 1e-05\n",
      "time: 180\n",
      "[111/120]\n",
      "train loss:0.759097208182017\n",
      "validation loss: 0.6001158434022245\n",
      "LR: 1e-05\n",
      "time: 180\n",
      "[112/120]\n",
      "train loss:0.7597965256373087\n",
      "validation loss: 0.6025358730723235\n",
      "LR: 1e-05\n",
      "time: 180\n",
      "[113/120]\n",
      "train loss:0.7614277501900991\n",
      "validation loss: 0.6017562803224754\n",
      "LR: 1e-05\n",
      "time: 180\n",
      "[114/120]\n",
      "train loss:0.7614206131299337\n",
      "validation loss: 0.6008686128315072\n",
      "LR: 1e-05\n",
      "time: 179\n",
      "[115/120]\n",
      "train loss:0.7579049118359884\n",
      "validation loss: 0.5989488924369653\n",
      "LR: 1e-05\n",
      "time: 181\n",
      "[116/120]\n",
      "train loss:0.7596454628308614\n",
      "validation loss: 0.6002979306911361\n",
      "LR: 1e-05\n",
      "time: 179\n",
      "[117/120]\n",
      "train loss:0.7613777073224386\n",
      "validation loss: 0.5997007588194553\n",
      "LR: 1e-05\n",
      "time: 182\n",
      "[118/120]\n",
      "train loss:0.7629937513669331\n",
      "validation loss: 0.6011572448139991\n",
      "LR: 1e-05\n",
      "time: 181\n",
      "[119/120]\n",
      "train loss:0.7597332004706064\n",
      "validation loss: 0.6041864989236608\n",
      "LR: 1e-05\n",
      "time: 180\n",
      "[120/120]\n",
      "train loss:0.7597411811351776\n",
      "validation loss: 0.6006382374032873\n",
      "LR: 1e-05\n",
      "time: 180\n",
      "-------------------------- Training finished in 21833s --------------------------\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataloader, \n",
    "    validation_dataloader, \n",
    "    epochs = config[\"epochs\"], \n",
    "    optimizer_name = config[\"optimizer\"], \n",
    "    lr_init = config[\"LR\"], \n",
    "    lr_policy = config[\"LR_policy\"], \n",
    "    criterion = config[\"criterion\"], \n",
    "    momentum = config[\"momentum\"],\n",
    "    resume = config[\"resume\"], \n",
    "    resume_epoch = config[\"resume_epoch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dbXlGrWCOuC"
   },
   "source": [
    "**Step 6.** Save the trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "T9GklbduXw5j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss files uploaded to s3\n",
      "model parameters uploaded to s3!, at  DL/models/gh_cg_tz_ng/attn_unet_dropout10\n"
     ]
    }
   ],
   "source": [
    "model.save(bucket=config[\"bucket\"], outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOxDlWhJBxYS"
   },
   "source": [
    "**Step 7.** Evaluate the trained model against the evaluation dataset and report a number of accuracy metrics in a csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9C-XLAYwXvqX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start evaluation --------------------------\n",
      "-------------------------- Evaluation finished in 40s --------------------------\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validation_dataloader, bucket=config[\"bucket\"], \n",
    "               outPrefix=config[\"prefix_out\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
