{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8e268b-4284-4890-94a2-2a73ad28ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66e77f4-fa15-45cc-80d5-fb4090bbbbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../../deeplearner'))\n",
    "sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5dec7b-1860-4118-8031-e2d6658e35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplearner.datatorch import *\n",
    "from deeplearner.utils import *\n",
    "from deeplearner.compiler import *\n",
    "from deeplearner.losses import *\n",
    "from deeplearner.models.unet_att_d import unet_att_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ee931b-dbec-41af-8fcf-f69a5307c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_reproducible(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9807a8cd-db9f-46b4-9ef1-c09b156b92a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yaml_config_path = \"/home/airg/skhallaghi/deeplearner_normalization_test/deeplearner/config/default_config_ex17.yaml\"\n",
    "\n",
    "with open(yaml_config_path, \"r\") as cfg:\n",
    "    config = yaml.load(cfg, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b2eb0a6-d204-45b2-bab1-2cb6aeabc352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# pprint.pprint(config, width=100, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb55b57c-a050-4846-b031-a86d582fbaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_tiles_list = [\"imagery/planet/tiles/2022/tile66177601_2022-03_buf179_cog.tif\",\n",
    "                      \"imagery/planet/tiles/2022/tile680962_2022-09_buf179_cog.tif\",\n",
    "                      \"imagery/planet/chips/v2/GH0765161_3261_6462_os.tif\",\n",
    "                      \"imagery/planet/chips/v2/GH0769863_2971_6476_os.tif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db322f29-8d6c-45a2-8058-5cf6f1a7a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_catalog = pd.read_csv(Path(config[\"source_dir\"]) / config[\"train_csv_name\"]).reset_index(drop=True)\n",
    "\n",
    "# name_filter = [\"drop\", (\"NG\")]  # drop or keep names beginning with\n",
    "\n",
    "# if name_filter:\n",
    "#     if name_filter[0] == \"drop\":\n",
    "#         train_catalog = train_catalog[~train_catalog.name.str.startswith(name_filter[1])]\\\n",
    "#             .reset_index(drop=True)\n",
    "#     else: \n",
    "#         train_catalog = train_catalog[catalog.name.str.startswith(name_filter[1])]\\\n",
    "#             .reset_index(drop=True)\n",
    "\n",
    "train_catalog = train_catalog[~train_catalog['dir_os'].isin(exclude_tiles_list)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64940a1e-1da2-4fb5-aa03-59fe4fc210c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalog shape: (4977, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dir_label</th>\n",
       "      <th>label_group</th>\n",
       "      <th>dir_gs</th>\n",
       "      <th>dir_os</th>\n",
       "      <th>usage</th>\n",
       "      <th>year</th>\n",
       "      <th>tile</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GH0635115</td>\n",
       "      <td>labels/GH0635115_3180_6263.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>images/gs/GH0635115_3180_6263_gs.tif</td>\n",
       "      <td>images/os/GH0635115_3180_6263_os.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GH0644758</td>\n",
       "      <td>labels/GH0644758_3589_6274.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>images/gs/GH0644758_3589_6274_gs.tif</td>\n",
       "      <td>images/os/GH0644758_3589_6274_os.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GH0325194</td>\n",
       "      <td>labels/GH0325194_3133_5833.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>images/gs/GH0325194_3133_5833_gs.tif</td>\n",
       "      <td>images/os/GH0325194_3133_5833_os.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GH0572047</td>\n",
       "      <td>labels/GH0572047_3005_6185.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>images/gs/GH0572047_3005_6185_gs.tif</td>\n",
       "      <td>images/os/GH0572047_3005_6185_os.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GH0460427</td>\n",
       "      <td>labels/GH0460427_3505_6034.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>images/gs/GH0460427_3505_6034_gs.tif</td>\n",
       "      <td>images/os/GH0460427_3505_6034_os.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                       dir_label  label_group  \\\n",
       "0  GH0635115  labels/GH0635115_3180_6263.tif            0   \n",
       "1  GH0644758  labels/GH0644758_3589_6274.tif            0   \n",
       "2  GH0325194  labels/GH0325194_3133_5833.tif            0   \n",
       "3  GH0572047  labels/GH0572047_3005_6185.tif            0   \n",
       "4  GH0460427  labels/GH0460427_3505_6034.tif            0   \n",
       "\n",
       "                                 dir_gs                                dir_os  \\\n",
       "0  images/gs/GH0635115_3180_6263_gs.tif  images/os/GH0635115_3180_6263_os.tif   \n",
       "1  images/gs/GH0644758_3589_6274_gs.tif  images/os/GH0644758_3589_6274_os.tif   \n",
       "2  images/gs/GH0325194_3133_5833_gs.tif  images/os/GH0325194_3133_5833_os.tif   \n",
       "3  images/gs/GH0572047_3005_6185_gs.tif  images/os/GH0572047_3005_6185_os.tif   \n",
       "4  images/gs/GH0460427_3505_6034_gs.tif  images/os/GH0460427_3505_6034_os.tif   \n",
       "\n",
       "   usage  year tile class  \n",
       "0  train  2018  NaN   NaN  \n",
       "1  train  2018  NaN   NaN  \n",
       "2  train  2018  NaN   NaN  \n",
       "3  train  2018  NaN   NaN  \n",
       "4  train  2018  NaN   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_catalog = train_catalog.head(300)\n",
    "print(f\"catalog shape: {train_catalog.shape}\")\n",
    "train_catalog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f00790-b1bf-4f6b-b03c-953415ca3d0c",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5fae8f-ac32-4ae2-affb-9234c4d7fb89",
   "metadata": {},
   "source": [
    "### Train/val loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab91b6e-872e-41a6-b6ee-7016d9facc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------4781 samples loaded in train dataset-----------\n"
     ]
    }
   ],
   "source": [
    "train_dataset = planetData(dataPath=config[\"source_dir\"],\n",
    "                           log_dir=config[\"log_dir\"], \n",
    "                           catalog=train_catalog,\n",
    "                           dataSize=config[\"patch_size\"], \n",
    "                           buffer=config[\"one_side_buffer\"],\n",
    "                           bufferComp=config[\"tile_buffer\"],  \n",
    "                           usage=\"train\",\n",
    "                           norm_stats_type=config[\"norm_stats_type\"],\n",
    "                           clip_val=config[\"clip_val\"],\n",
    "                           global_stats=config[\"global_stats\"], \n",
    "                           nodata_val_ls=config[\"nodata\"],\n",
    "                           imgPathCols=config[\"img_path_cols\"], \n",
    "                           labelPathCol=config[\"label_path_col\"], \n",
    "                           labelGroup=config[\"train_group\"], \n",
    "                           deRotate=config[\"rotationDegree\"], \n",
    "                           bShiftSubs=config[\"bshift_band_grouping\"], \n",
    "                           trans=config[\"transformations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2267168-09c9-49ab-b997-acd22a7668d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def check_images_for_zeros_and_nans(train_dataset):\n",
    "#     # Initialize a dictionary to hold the count of zeros and NaNs for each image\n",
    "#     img_report = {}\n",
    "\n",
    "#     # Iterate through the dataset\n",
    "#     for index, (img, lbl, mask) in enumerate(train_dataset):\n",
    "#         # Count the number of zeros in the image\n",
    "#         zeros_count = np.count_nonzero(img == 0)\n",
    "        \n",
    "#         # Count the number of NaNs in the image\n",
    "#         nans_count = np.count_nonzero(np.isnan(img))\n",
    "        \n",
    "#         # Store the counts in the report dictionary with the image index as the key\n",
    "#         img_report[index] = {'zeros': zeros_count, 'nans': nans_count}\n",
    "\n",
    "#         # Optionally, you can print out the report for each image\n",
    "#         print(f\"Image {index}: Zeros = {zeros_count}, NaNs = {nans_count}\")\n",
    "\n",
    "#     return img_report\n",
    "\n",
    "# check_images_for_zeros_and_nans(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d2d4a9-ea94-4542-9e5a-41b6cc9da0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=config[\"train_batch\"], \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace4f673-9393-4250-a67c-14a477ec8bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------196 samples loaded in validate dataset-----------\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = planetData(dataPath=config[\"source_dir\"],\n",
    "                                log_dir=config[\"log_dir\"],\n",
    "                                catalog=train_catalog, \n",
    "                                dataSize=config[\"patch_size\"], \n",
    "                                buffer = config[\"one_side_buffer\"],\n",
    "                                bufferComp = config[\"tile_buffer\"],\n",
    "                                usage = \"validate\",\n",
    "                                norm_stats_type=config[\"norm_stats_type\"],\n",
    "                                clip_val=config[\"clip_val\"],\n",
    "                                global_stats=config[\"global_stats\"], \n",
    "                                nodata_val_ls=config[\"nodata\"],\n",
    "                                imgPathCols = config[\"img_path_cols\"],\n",
    "                                labelPathCol = config[\"label_path_col\"], \n",
    "                                labelGroup=config[\"validate_group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91799285-ff15-465e-951e-708313a1c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataloader = DataLoader(validation_dataset, \n",
    "                                 batch_size=config[\"validate_batch\"], \n",
    "                                 shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2027b6-4e77-44fd-9d43-7488cca325c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#images, labels = next(iter(validation_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c0149a1-3778-4e68-8df5-4ef326d62f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_att_d(n_classes=config[\"n_classes\"],\n",
    "                   in_channels=config[\"channels\"],\n",
    "                   filter_config=config[\"stage_width\"],\n",
    "                   block_num=config[\"block_num\"],\n",
    "                   dropout_rate=config[\"train_dropout_rate\"],\n",
    "                   dropout_type=config[\"dropout_type\"],\n",
    "                  use_skipAtt=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f5773fe-bdf9-471f-a5d5-d5c7503c3955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Vanilla Model compiled successfully ----------\n",
      "----------GPU available----------\n",
      "total number of trainable parameters: 157.9M\n"
     ]
    }
   ],
   "source": [
    "compiled_model = ModelCompiler(model,\n",
    "                               working_dir=config[\"working_dir\"],\n",
    "                               out_dir=config[\"out_dir\"],\n",
    "                               buffer = config[\"one_side_buffer\"],\n",
    "                               class_mapping=config[\"class_mapping\"],\n",
    "                               gpuDevices = config[\"gpu_devices\"], \n",
    "                               params_init = config[\"params_init_path\"],\n",
    "                               freeze_params = config[\"freeze_layer_ls\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22e1a267-3349-41a0-b2f4-efbc6866a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_name = config['criterion']['name']\n",
    "weight = config['criterion']['weight']\n",
    "ignore_index = config['criterion']['ignore_index']\n",
    "gamma = config['criterion']['gamma']\n",
    "alpha = config['criterion']['alpha']\n",
    "\n",
    "if criterion_name == 'TverskyFocalLoss':\n",
    "    criterion = TverskyFocalLoss(weight=weight, ignore_index=ignore_index, alpha=alpha, gamma=gamma)\n",
    "elif criterion_name == \"LocallyWeightedTverskyFocalLoss\":\n",
    "    criterion = LocallyWeightedTverskyFocalLoss(ignore_index=ignore_index, alpha=alpha, gamma=gamma)\n",
    "elif criterion_name == \"LocallyWeightedTverskyFocalCELoss\":\n",
    "    criterion = LocallyWeightedTverskyFocalCELoss(ignore_index=ignore_index, tversky_alpha=alpha, \n",
    "                                                  tversky_gamma=gamma)\n",
    "else:\n",
    "    raise ValueError(\"Invalid 'criterion_name'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29aea0-6de1-4aeb-ad3a-cc43b5d543f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start training --------------------------\n",
      "[1/120]\n",
      "Using SGD\n",
      "train loss:0.7185809536774953\n",
      "validation loss: 0.732886292496506\n",
      "LR: 0.014911281229302152\n",
      "time: 182\n",
      "[2/120]\n",
      "Using SGD\n",
      "train loss:0.7018305639425914\n",
      "validation loss: 0.6906670672552926\n",
      "LR: 0.014911281229302152\n",
      "time: 134\n",
      "[3/120]\n",
      "Using SGD\n",
      "train loss:0.6974987590312958\n",
      "validation loss: 0.7167619332975271\n",
      "LR: 0.014822277119245861\n",
      "time: 132\n",
      "[4/120]\n",
      "Using SGD\n",
      "train loss:0.6961131000518799\n",
      "validation loss: 0.6922978548979273\n",
      "LR: 0.014732984097201645\n",
      "time: 135\n",
      "[5/120]\n",
      "Using SGD\n",
      "train loss:0.6977688380082449\n",
      "validation loss: 0.6892845636727859\n",
      "LR: 0.014643398511944045\n",
      "time: 129\n",
      "[6/120]\n",
      "Using SGD\n",
      "train loss:0.6923490635553996\n",
      "validation loss: 0.7216459336329479\n",
      "LR: 0.01455351663116347\n",
      "time: 133\n",
      "[7/120]\n",
      "Using SGD\n",
      "train loss:0.6932181545098622\n",
      "validation loss: 0.7177192985403295\n",
      "LR: 0.014463334638874763\n",
      "time: 134\n",
      "[8/120]\n",
      "Using SGD\n",
      "train loss:0.68803014198939\n",
      "validation loss: 0.7025590922151294\n",
      "LR: 0.01437284863271719\n",
      "time: 133\n",
      "[9/120]\n",
      "Using SGD\n",
      "train loss:0.6892521138985952\n",
      "validation loss: 0.6957066521352652\n",
      "LR: 0.014282054621140202\n",
      "time: 135\n",
      "[10/120]\n",
      "Using SGD\n",
      "train loss:0.6859264202912648\n",
      "validation loss: 0.6819533206978623\n",
      "LR: 0.014190948520468961\n",
      "time: 134\n",
      "[11/120]\n",
      "Using SGD\n",
      "train loss:0.6869767832756043\n",
      "validation loss: 0.7188949618412523\n",
      "LR: 0.014099526151843247\n",
      "time: 136\n",
      "[12/120]\n",
      "Using SGD\n",
      "train loss:0.6807913060983022\n",
      "validation loss: 0.6726705511005557\n",
      "LR: 0.01400778323802298\n",
      "time: 134\n",
      "[13/120]\n",
      "Using SGD\n",
      "train loss:0.6804350638389587\n",
      "validation loss: 0.6689762984003339\n",
      "LR: 0.01391571540005309\n",
      "time: 132\n",
      "[14/120]\n",
      "Using SGD\n",
      "train loss:0.6747838882605235\n",
      "validation loss: 0.6619885858832574\n",
      "LR: 0.013823318153780116\n",
      "time: 135\n",
      "[15/120]\n",
      "Using SGD\n",
      "train loss:0.6737932753562927\n",
      "validation loss: 0.6449320480531576\n",
      "LR: 0.01373058690621225\n",
      "time: 134\n",
      "[16/120]\n",
      "Using SGD\n",
      "train loss:0.6693096705277761\n",
      "validation loss: 0.6918133646249771\n",
      "LR: 0.013637516951714156\n",
      "time: 133\n",
      "[17/120]\n",
      "Using SGD\n",
      "train loss:0.6689117817083995\n",
      "validation loss: 0.7032965090201826\n",
      "LR: 0.013544103468027223\n",
      "time: 133\n",
      "[18/120]\n",
      "Using SGD\n",
      "train loss:0.6634419810771942\n",
      "validation loss: 0.6336315471907051\n",
      "LR: 0.013450341512105272\n",
      "time: 132\n",
      "[19/120]\n",
      "Using SGD\n",
      "train loss:0.6595793529351552\n",
      "validation loss: 0.6342203899913904\n",
      "LR: 0.013356226015755104\n",
      "time: 136\n",
      "[20/120]\n",
      "Using SGD\n",
      "train loss:0.6578873352209726\n",
      "validation loss: 0.6315991781195816\n",
      "LR: 0.01326175178107052\n",
      "time: 131\n",
      "[21/120]\n",
      "Using SGD\n",
      "train loss:0.6590535696347555\n",
      "validation loss: 0.6406807510220275\n",
      "LR: 0.013166913475647619\n",
      "time: 133\n",
      "[22/120]\n",
      "Using SGD\n",
      "train loss:0.65928155819575\n",
      "validation loss: 0.6417340791347076\n",
      "LR: 0.013071705627568396\n",
      "time: 138\n",
      "[23/120]\n",
      "Using SGD\n",
      "train loss:0.6570856650670369\n",
      "validation loss: 0.6227650088923318\n",
      "LR: 0.012976122620138614\n",
      "time: 130\n",
      "[24/120]\n",
      "Using SGD\n",
      "train loss:0.6552314523855846\n",
      "validation loss: 0.6298382084588615\n",
      "LR: 0.012880158686365032\n",
      "time: 133\n",
      "[25/120]\n",
      "Using SGD\n",
      "train loss:0.652890408039093\n",
      "validation loss: 0.6252934561700237\n",
      "LR: 0.012783807903155931\n",
      "time: 133\n",
      "[26/120]\n",
      "Using SGD\n",
      "train loss:0.6496421054999033\n",
      "validation loss: 0.6266215902810194\n",
      "LR: 0.01268706418522763\n",
      "time: 133\n",
      "[27/120]\n",
      "Using SGD\n",
      "train loss:0.6499779884020488\n",
      "validation loss: 0.610315814614296\n",
      "LR: 0.01258992127869852\n",
      "time: 133\n",
      "[28/120]\n",
      "Using SGD\n",
      "train loss:0.6465276066462199\n",
      "validation loss: 0.6141237069149407\n",
      "LR: 0.012492372754350603\n",
      "time: 132\n",
      "[29/120]\n",
      "Using SGD\n",
      "train loss:0.6453997882207235\n",
      "validation loss: 0.6195188958425911\n",
      "LR: 0.012394412000537125\n",
      "time: 132\n",
      "[30/120]\n",
      "Using SGD\n",
      "train loss:0.6460463492075602\n",
      "validation loss: 0.6118980381561785\n",
      "LR: 0.012296032215713069\n",
      "time: 133\n",
      "[31/120]\n",
      "Using SGD\n",
      "train loss:0.6456602311134338\n",
      "validation loss: 0.6328657062686219\n",
      "LR: 0.012197226400563662\n",
      "time: 133\n",
      "[32/120]\n",
      "Using SGD\n",
      "train loss:0.6467792455355327\n",
      "validation loss: 0.602371620280402\n",
      "LR: 0.01209798734970382\n",
      "time: 133\n",
      "[33/120]\n",
      "Using SGD\n",
      "train loss:0.6390553116798401\n",
      "validation loss: 0.6006925723382405\n",
      "LR: 0.01199830764291951\n",
      "time: 135\n",
      "[34/120]\n",
      "Using SGD\n",
      "train loss:0.6393493648370107\n",
      "validation loss: 0.6156173147717301\n",
      "LR: 0.01189817963591948\n",
      "time: 136\n",
      "[35/120]\n",
      "Using SGD\n",
      "train loss:0.6409376895427704\n",
      "validation loss: 0.6000458290990518\n",
      "LR: 0.011797595450563265\n",
      "time: 133\n",
      "[36/120]\n",
      "Using SGD\n",
      "train loss:0.6317285319169362\n",
      "validation loss: 0.6006039411437755\n",
      "LR: 0.011696546964528516\n",
      "time: 131\n",
      "[37/120]\n",
      "Using SGD\n",
      "train loss:0.638290015856425\n",
      "validation loss: 0.6832412642483808\n",
      "LR: 0.011595025800377568\n",
      "time: 133\n",
      "[38/120]\n",
      "Using SGD\n",
      "train loss:0.6360769776503244\n",
      "validation loss: 0.5890792641712694\n",
      "LR: 0.011493023313979668\n",
      "time: 131\n",
      "[39/120]\n",
      "Using SGD\n",
      "train loss:0.6310669688383738\n",
      "validation loss: 0.5861845496965914\n",
      "LR: 0.01139053058224157\n",
      "time: 134\n",
      "[40/120]\n",
      "Using SGD\n",
      "train loss:0.6309330427646637\n",
      "validation loss: 0.5823554603420958\n",
      "LR: 0.011287538390094918\n",
      "time: 133\n",
      "[41/120]\n",
      "Using SGD\n",
      "train loss:0.6256584099928538\n",
      "validation loss: 0.5969630239569411\n",
      "LR: 0.011184037216684314\n",
      "time: 136\n",
      "[42/120]\n",
      "Using SGD\n",
      "train loss:0.6302884836991628\n",
      "validation loss: 0.571127150435837\n",
      "LR: 0.011080017220694788\n",
      "time: 133\n",
      "[43/120]\n",
      "Using SGD\n",
      "train loss:0.6273769692579905\n",
      "validation loss: 0.5870092897390833\n",
      "LR: 0.010975468224751771\n",
      "time: 134\n",
      "[44/120]\n",
      "Using SGD\n",
      "train loss:0.6275403360525768\n",
      "validation loss: 0.5813428890340182\n",
      "LR: 0.01087037969882039\n",
      "time: 131\n",
      "[45/120]\n",
      "Using SGD\n",
      "train loss:0.62577880859375\n",
      "validation loss: 0.560452724597892\n",
      "LR: 0.010764740742523963\n",
      "time: 136\n",
      "[46/120]\n",
      "Using SGD\n",
      "train loss:0.6271657145023346\n",
      "validation loss: 0.581219772295076\n",
      "LR: 0.010658540066293838\n",
      "time: 132\n",
      "[47/120]\n",
      "Using SGD\n",
      "train loss:0.6233523790041605\n",
      "validation loss: 0.5790696588097787\n",
      "LR: 0.0105517659712541\n",
      "time: 134\n",
      "[48/120]\n",
      "Using SGD\n",
      "train loss:0.6228645793596903\n",
      "validation loss: 0.5867556765371439\n",
      "LR: 0.010444406327735066\n",
      "time: 134\n",
      "[49/120]\n",
      "Using SGD\n",
      "train loss:0.6213682647546133\n",
      "validation loss: 0.5845445063041181\n",
      "LR: 0.010336448552298795\n",
      "time: 135\n",
      "[50/120]\n",
      "Using SGD\n",
      "train loss:0.6214410909016927\n",
      "validation loss: 0.5651714631489345\n",
      "LR: 0.010227879583147826\n",
      "time: 135\n",
      "[51/120]\n",
      "Using SGD\n",
      "train loss:0.6222801172733307\n",
      "validation loss: 0.5746195258534684\n",
      "LR: 0.01011868585377488\n",
      "time: 133\n",
      "[52/120]\n",
      "Using SGD\n",
      "train loss:0.6243924073378245\n",
      "validation loss: 0.5678848514751512\n",
      "LR: 0.010008853264696197\n",
      "time: 134\n",
      "[53/120]\n",
      "Using SGD\n",
      "train loss:0.6194038752714793\n",
      "validation loss: 0.5681843365333519\n",
      "LR: 0.00989836715309418\n",
      "time: 134\n",
      "[54/120]\n",
      "Using SGD\n",
      "train loss:0.622858099937439\n",
      "validation loss: 0.5668022161235615\n",
      "LR: 0.009787212260175865\n",
      "time: 137\n",
      "[55/120]\n",
      "Using SGD\n",
      "train loss:0.6224571470419565\n",
      "validation loss: 0.5594266554226681\n",
      "LR: 0.0096753726960321\n",
      "time: 129\n",
      "[56/120]\n",
      "Using SGD\n",
      "train loss:0.6198838078975677\n",
      "validation loss: 0.5574243844163661\n",
      "LR: 0.00956283190175787\n",
      "time: 138\n",
      "[57/120]\n",
      "Using SGD\n",
      "train loss:0.6160669660568238\n",
      "validation loss: 0.5621047442664906\n",
      "LR: 0.00944957260856638\n",
      "time: 136\n",
      "[58/120]\n",
      "Using SGD\n",
      "train loss:0.6258543745676677\n",
      "validation loss: 0.5832078447755502\n",
      "LR: 0.00933557679359808\n",
      "time: 136\n",
      "[59/120]\n",
      "Using SGD\n",
      "train loss:0.6138479767243067\n",
      "validation loss: 0.5685518922246232\n",
      "LR: 0.009220825632089721\n",
      "time: 135\n",
      "[60/120]\n",
      "Using SGD\n",
      "train loss:0.6097202444076538\n",
      "validation loss: 0.5480754156501926\n",
      "LR: 0.009105299445527616\n",
      "time: 133\n",
      "[61/120]\n",
      "Using SGD\n",
      "train loss:0.6141293815771739\n",
      "validation loss: 0.5539750389906825\n",
      "LR: 0.00898897764536224\n",
      "time: 132\n",
      "[62/120]\n",
      "Using SGD\n",
      "train loss:0.6092944757143657\n",
      "validation loss: 0.5555374261980154\n",
      "LR: 0.008871838671807394\n",
      "time: 134\n",
      "[63/120]\n",
      "Using SGD\n",
      "train loss:0.6098994259039561\n",
      "validation loss: 0.5709917852464987\n",
      "LR: 0.00875385992718517\n",
      "time: 134\n",
      "[64/120]\n",
      "Using SGD\n",
      "train loss:0.6103551419576009\n",
      "validation loss: 0.5556145471577741\n",
      "LR: 0.00863501770320629\n",
      "time: 133\n",
      "[65/120]\n",
      "Using SGD\n",
      "train loss:0.6135678593317667\n",
      "validation loss: 0.5621716456145657\n",
      "LR: 0.008515287101492741\n",
      "time: 131\n",
      "[66/120]\n",
      "Using SGD\n",
      "train loss:0.6134659989674887\n",
      "validation loss: 0.5448125406187407\n",
      "LR: 0.008394641946553342\n",
      "time: 132\n",
      "[67/120]\n",
      "Using SGD\n",
      "train loss:0.6045516610145569\n",
      "validation loss: 0.5566750500275164\n",
      "LR: 0.008273054690311173\n",
      "time: 133\n",
      "[68/120]\n",
      "Using SGD\n",
      "train loss:0.6089187626043956\n",
      "validation loss: 0.5436253112797834\n",
      "LR: 0.008150496307151086\n",
      "time: 134\n",
      "[69/120]\n",
      "Using SGD\n",
      "train loss:0.6088603897889455\n",
      "validation loss: 0.5735103582241097\n",
      "LR: 0.00802693617830246\n",
      "time: 136\n",
      "[70/120]\n",
      "Using SGD\n",
      "train loss:0.6042730023463567\n",
      "validation loss: 0.5448036656087759\n",
      "LR: 0.007902341964192396\n",
      "time: 133\n",
      "[71/120]\n",
      "Using SGD\n",
      "train loss:0.6065435270468394\n",
      "validation loss: 0.5456621400555786\n",
      "LR: 0.007776679463192147\n",
      "time: 136\n",
      "[72/120]\n",
      "Using SGD\n",
      "train loss:0.6079457362492879\n",
      "validation loss: 0.546180501276133\n",
      "LR: 0.0076499124549278975\n",
      "time: 134\n",
      "[73/120]\n",
      "Using SGD\n",
      "train loss:0.6033300765355428\n",
      "validation loss: 0.5333858789229879\n",
      "LR: 0.0075220025260277976\n",
      "time: 133\n",
      "[74/120]\n",
      "Using SGD\n",
      "train loss:0.6021312626202902\n",
      "validation loss: 0.5623362103895265\n",
      "LR: 0.007392908875819534\n",
      "time: 134\n",
      "[75/120]\n",
      "Using SGD\n",
      "train loss:0.6076019090414048\n",
      "validation loss: 0.5603414366439897\n",
      "LR: 0.007262588099063932\n",
      "time: 133\n",
      "[76/120]\n",
      "Using SGD\n",
      "train loss:0.6007495089371999\n",
      "validation loss: 0.5534252962287591\n",
      "LR: 0.007130993942292971\n",
      "time: 134\n",
      "[77/120]\n",
      "Using SGD\n",
      "train loss:0.5982982540130615\n",
      "validation loss: 0.5399444030255688\n",
      "LR: 0.0069980770296945265\n",
      "time: 134\n",
      "[78/120]\n",
      "Using SGD\n",
      "train loss:0.6027976930141449\n",
      "validation loss: 0.5531131632778109\n",
      "LR: 0.0068637845537236845\n",
      "time: 133\n",
      "[79/120]\n",
      "Using SGD\n",
      "train loss:0.5994133524099986\n",
      "validation loss: 0.5503677014185457\n",
      "LR: 0.006728059924687239\n",
      "time: 134\n",
      "[80/120]\n",
      "Using SGD\n",
      "train loss:0.6011708160241445\n",
      "validation loss: 0.5390279197267124\n",
      "LR: 0.006590842372399019\n",
      "time: 134\n",
      "[81/120]\n",
      "Using SGD\n",
      "train loss:0.5996364883581797\n",
      "validation loss: 0.5603982718015204\n",
      "LR: 0.0064520664915803305\n",
      "time: 135\n",
      "[82/120]\n",
      "Using SGD\n",
      "train loss:0.598574857711792\n",
      "validation loss: 0.5241968022013197\n",
      "LR: 0.006311661720905451\n",
      "time: 134\n",
      "[83/120]\n",
      "Using SGD\n",
      "train loss:0.6003140119711557\n",
      "validation loss: 0.5404803676872837\n",
      "LR: 0.006169551743364571\n",
      "time: 135\n",
      "[84/120]\n",
      "Using SGD\n",
      "train loss:0.5945915945370992\n",
      "validation loss: 0.5395027402104163\n",
      "LR: 0.006025653792800044\n",
      "time: 134\n",
      "[85/120]\n",
      "Using SGD\n",
      "train loss:0.5950435646375021\n",
      "validation loss: 0.5512555284159524\n",
      "LR: 0.0058798778478823055\n",
      "time: 133\n",
      "[86/120]\n",
      "Using SGD\n",
      "train loss:0.5964643305540085\n",
      "validation loss: 0.5280311872460404\n",
      "LR: 0.005732125690179264\n",
      "time: 134\n",
      "[87/120]\n",
      "Using SGD\n",
      "train loss:0.598431389927864\n",
      "validation loss: 0.5379768500522691\n",
      "LR: 0.005582289796992443\n",
      "time: 133\n",
      "[88/120]\n",
      "Using SGD\n",
      "train loss:0.5990414311488469\n",
      "validation loss: 0.5389668801609351\n",
      "LR: 0.005430252031804509\n",
      "time: 135\n",
      "[89/120]\n",
      "Using SGD\n",
      "train loss:0.5983572789033254\n",
      "validation loss: 0.531645519392831\n",
      "LR: 0.005275882084828189\n",
      "time: 132\n",
      "[90/120]\n",
      "Using SGD\n",
      "train loss:0.5954813182353973\n",
      "validation loss: 0.526791969428257\n",
      "LR: 0.005119035602297835\n",
      "time: 135\n",
      "[91/120]\n",
      "Using SGD\n",
      "train loss:0.6007150838772456\n",
      "validation loss: 0.5409629080368548\n",
      "LR: 0.004959551924396906\n",
      "time: 137\n",
      "[92/120]\n",
      "Using SGD\n",
      "train loss:0.5967809768517812\n",
      "validation loss: 0.5272716811420967\n",
      "LR: 0.004797251325998936\n",
      "time: 133\n",
      "[93/120]\n",
      "Using SGD\n",
      "train loss:0.5931226921081543\n",
      "validation loss: 0.5247774575741924\n",
      "LR: 0.004631931618615571\n",
      "time: 132\n",
      "[94/120]\n",
      "Using SGD\n",
      "train loss:0.5938144155343373\n",
      "validation loss: 0.5281421899491426\n",
      "LR: 0.0044633639213613905\n",
      "time: 135\n",
      "[95/120]\n",
      "Using SGD\n",
      "train loss:0.5935897403955459\n",
      "validation loss: 0.5357948337890663\n",
      "LR: 0.004291287335988882\n",
      "time: 134\n",
      "[96/120]\n",
      "Using SGD\n",
      "train loss:0.5936505858103435\n",
      "validation loss: 0.5249085443056359\n",
      "LR: 0.004115402154370512\n",
      "time: 135\n",
      "[97/120]\n",
      "Using SGD\n",
      "train loss:0.5900493053595225\n",
      "validation loss: 0.5289176992919981\n",
      "LR: 0.003935361067014102\n",
      "time: 135\n",
      "[98/120]\n",
      "Using SGD\n",
      "train loss:0.5934761766592661\n",
      "validation loss: 0.5260530187159168\n",
      "LR: 0.003750757596042156\n",
      "time: 137\n",
      "[99/120]\n",
      "Using SGD\n",
      "train loss:0.5912073930104573\n",
      "validation loss: 0.5363321947504063\n",
      "LR: 0.003561110589629707\n",
      "time: 132\n",
      "[100/120]\n",
      "Using SGD\n",
      "train loss:0.5879692874352137\n",
      "validation loss: 0.5322502472875069\n",
      "LR: 0.0033658429867139406\n",
      "time: 135\n",
      "[101/120]\n",
      "Using SGD\n",
      "train loss:0.594654586315155\n",
      "validation loss: 0.5254648805272822\n",
      "LR: 0.0031642520028542917\n",
      "time: 135\n",
      "[102/120]\n",
      "Using SGD\n",
      "train loss:0.5899201770623524\n",
      "validation loss: 0.5268993059895477\n",
      "LR: 0.002955466031624696\n",
      "time: 130\n",
      "[103/120]\n",
      "Using SGD\n",
      "train loss:0.5935237248738606\n",
      "validation loss: 0.5310966618815247\n",
      "LR: 0.0027383801363460012\n",
      "time: 129\n",
      "[104/120]\n",
      "Using SGD\n",
      "train loss:0.5846604917446773\n",
      "validation loss: 0.526167629780818\n",
      "LR: 0.00251155533201405\n",
      "time: 134\n",
      "[105/120]\n",
      "Using SGD\n",
      "train loss:0.5885781427224477\n",
      "validation loss: 0.5310518863249798\n",
      "LR: 0.0022730528703992572\n",
      "time: 130\n",
      "[106/120]\n",
      "Using SGD\n",
      "train loss:0.5889605224132538\n",
      "validation loss: 0.5214157043671122\n",
      "LR: 0.002020142705740501\n",
      "time: 134\n",
      "[107/120]\n",
      "Using SGD\n",
      "train loss:0.5845818507671356\n",
      "validation loss: 0.5206352490551618\n",
      "LR: 0.0017487429490732867\n",
      "time: 136\n",
      "[108/120]\n",
      "Using SGD\n",
      "train loss:0.5859245975812276\n",
      "validation loss: 0.5141144762842023\n",
      "LR: 0.0014521990430763651\n",
      "time: 134\n",
      "[109/120]\n",
      "Using SGD\n",
      "train loss:0.5796721627314886\n",
      "validation loss: 0.522012355376263\n",
      "LR: 0.0011180666519588962\n",
      "time: 135\n",
      "[110/120]\n",
      "Using SGD\n",
      "train loss:0.5844176413615545\n",
      "validation loss: 0.5225164996726173\n",
      "LR: 0.0007161490635161397\n",
      "time: 132\n",
      "[111/120]\n",
      "Using SGD\n",
      "train loss:0.5814874895413716\n",
      "validation loss: 0.5146699693738198\n",
      "LR: 1e-05\n",
      "time: 137\n",
      "[112/120]\n",
      "Using SGD\n"
     ]
    }
   ],
   "source": [
    "compiled_model.fit(train_dataloader, \n",
    "                   validation_dataloader, \n",
    "                   epochs = config[\"epochs\"],\n",
    "                   optimizer_name = config[\"optimizer\"],\n",
    "                   lr_init = config[\"learnrate_init\"],\n",
    "                   lr_policy = config[\"LR_policy\"],\n",
    "                   criterion = criterion,\n",
    "                   momentum = config[\"momentum\"],\n",
    "                   resume = config[\"resume\"],\n",
    "                   resume_epoch = config[\"resume_epoch\"],\n",
    "                   **config[\"fitting_prams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130c68b-6747-4c79-8d86-a3866457f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model.save(save_object=\"params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf85743-70a5-4dd1-af9b-047577f14842",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compiled_model.accuracy_evaluation(validation_dataloader, unknown_class_idx=None, filename=config[\"val_metric_fname\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cfa4f-cafc-4168-be48-c38db6e29936",
   "metadata": {},
   "source": [
    "## Prediction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7200569-72d6-4d2a-ae4f-7b758c932b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(Path(config[\"pred_data_dir\"]) / config[\"pred_csv_name\"], index_col=0)\n",
    "tile_count = len(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e381bff3-80c5-4618-bf0a-fa1305458d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalog shape: (20, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile</th>\n",
       "      <th>tile_col</th>\n",
       "      <th>tile_row</th>\n",
       "      <th>aoi</th>\n",
       "      <th>image_dir</th>\n",
       "      <th>label_dir</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>487103</td>\n",
       "      <td>310</td>\n",
       "      <td>543</td>\n",
       "      <td>1</td>\n",
       "      <td>tile487103_2018-12_composite.tif</td>\n",
       "      <td>lbl_487103_2018.tif</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487103</td>\n",
       "      <td>310</td>\n",
       "      <td>543</td>\n",
       "      <td>1</td>\n",
       "      <td>tile487103_2019-06_2019-11_buf179_cog.tif</td>\n",
       "      <td>lbl_487103_2019.tif</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487103</td>\n",
       "      <td>310</td>\n",
       "      <td>543</td>\n",
       "      <td>1</td>\n",
       "      <td>tile487103_2020-11_buf179_cog.tif</td>\n",
       "      <td>lbl_487103_2020.tif</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487103</td>\n",
       "      <td>310</td>\n",
       "      <td>543</td>\n",
       "      <td>1</td>\n",
       "      <td>tile487103_2021-11_buf179_cog.tif</td>\n",
       "      <td>lbl_487103_2021.tif</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487103</td>\n",
       "      <td>310</td>\n",
       "      <td>543</td>\n",
       "      <td>1</td>\n",
       "      <td>tile487103_2022-11_buf179_cog.tif</td>\n",
       "      <td>lbl_487103_2022.tif</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tile  tile_col  tile_row  aoi                                  image_dir  \\\n",
       "0  487103       310       543    1           tile487103_2018-12_composite.tif   \n",
       "1  487103       310       543    1  tile487103_2019-06_2019-11_buf179_cog.tif   \n",
       "2  487103       310       543    1          tile487103_2020-11_buf179_cog.tif   \n",
       "3  487103       310       543    1          tile487103_2021-11_buf179_cog.tif   \n",
       "4  487103       310       543    1          tile487103_2022-11_buf179_cog.tif   \n",
       "\n",
       "             label_dir    type  \n",
       "0  lbl_487103_2018.tif  center  \n",
       "1  lbl_487103_2019.tif  center  \n",
       "2  lbl_487103_2020.tif  center  \n",
       "3  lbl_487103_2021.tif  center  \n",
       "4  lbl_487103_2022.tif  center  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"catalog shape: {catalog.shape}\")\n",
    "catalog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f170584-4cb3-43c2-88b3-03b448f9fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prediction_data(usage, catalog_row):\n",
    "    dataset = planetData(dataPath=config[\"pred_data_dir\"],\n",
    "                         log_dir=config[\"log_dir\"],\n",
    "                         catalog=catalog, \n",
    "                         dataSize=config[\"pred_patch_size\"], \n",
    "                         buffer=config[\"pred_buffer\"], \n",
    "                         bufferComp=config[\"pred_composite_buffer\"], \n",
    "                         usage=usage,\n",
    "                         norm_stats_type=config[\"norm_stats_type\"],\n",
    "                         clip_val=config[\"clip_val\"],\n",
    "                         global_stats=config[\"global_stats\"], \n",
    "                         nodata_val_ls=config[\"nodata\"],\n",
    "                         imgPathCols=config[\"pred_img_path_cols\"],\n",
    "                         catalogIndex=catalog_row)\n",
    "    data_loader = DataLoader(dataset, batch_size=config[\"pred_batch\"], shuffle=False)\n",
    "    meta = dataset.meta\n",
    "    tile = dataset.tile\n",
    "    year = dataset.year\n",
    "    return data_loader, meta, tile, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa6baef9-2057-4c2d-9edd-5c13aeeb50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 87s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 87s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 89s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 85s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 88s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 84s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 90s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 87s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 87s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 87s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 89s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 87s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 87s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 86s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 84s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 85s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 90s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 87s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 89s --------------------------\n",
      "-------------------------- Start prediction --------------------------\n",
      "-------------------------- Prediction finished in 88s --------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(tile_count):\n",
    "    pred_data = load_prediction_data(\"predict\", i)\n",
    "    compiled_model.predict(pred_data, outPrefix=config[\"output_prefix\"], predBuffer=config[\"pred_buffer\"],\n",
    "                           mc_samples=config[\"num_mc_trials\"], shrinkBuffer=config[\"shrink_buffer\"], \n",
    "                           hardening_threshold=config[\"hardening_threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94099075-dcb9-4d01-b38b-bc53b6f32ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
